{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.python.framework.ops import reset_default_graph\n",
    "import os\n",
    "import subprocess\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "def onehot(t, num_classes):\n",
    "    out = np.zeros((t.shape[0], num_classes))\n",
    "    for row, col in enumerate(t):\n",
    "        out[row, col] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class load_data():\n",
    "    # data_train, data_test and le are public\n",
    "    def __init__(self, train_path, test_path, image_paths, image_shape=(128, 128)):\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        image_paths = image_paths\n",
    "        image_shape = image_shape\n",
    "        self._load(train_df, test_df, image_paths, image_shape)\n",
    "        \n",
    "    def _load(self, train_df, test_df, image_paths, image_shape):\n",
    "        print(\"loading data ...\")\n",
    "        # load train.csv\n",
    "        path_dict = self._path_to_dict(image_paths) # numerate image paths and make it a dict\n",
    "        # merge image paths with data frame\n",
    "        train_image_df = self._merge_image_df(train_df, path_dict)\n",
    "        test_image_df = self._merge_image_df(test_df, path_dict)\n",
    "        # label encoder-decoder (self. because we need it later)\n",
    "        self.le = LabelEncoder().fit(train_image_df['species'])\n",
    "        # labels for train\n",
    "        t_train = self.le.transform(train_image_df['species'])\n",
    "        # getting data\n",
    "        train_data = self._make_dataset(train_image_df, image_shape, t_train)\n",
    "        test_data = self._make_dataset(test_image_df, image_shape)        \n",
    "        # need to reformat the train for validation split reasons in the batch_generator\n",
    "        self.train = self._format_dataset(train_data, for_train=True)\n",
    "        self.test = self._format_dataset(test_data, for_train=False)\n",
    "        print(\"data loaded\") \n",
    "        \n",
    "\n",
    "    def _path_to_dict(self, image_paths):\n",
    "        path_dict = dict()\n",
    "        for image_path in image_paths:\n",
    "            num_path = int(os.path.basename(image_path[:-4]))\n",
    "            path_dict[num_path] = image_path\n",
    "        return path_dict\n",
    "\n",
    "    def _merge_image_df(self, df, path_dict):\n",
    "        split_path_dict = dict()\n",
    "        for index, row in df.iterrows():\n",
    "            split_path_dict[row['id']] = path_dict[row['id']]\n",
    "        image_frame = pd.DataFrame(list(split_path_dict.values()), columns=['image'])\n",
    "        df_image =  pd.concat([image_frame, df], axis=1)\n",
    "        return df_image\n",
    "    \n",
    "\n",
    "    def _make_dataset(self, df, image_shape, t_train=None):\n",
    "        if t_train is not None:\n",
    "            print(\"loading train ...\")\n",
    "        else:\n",
    "            print(\"loading test ...\")\n",
    "        # make dataset\n",
    "        data = dict()\n",
    "        # merge image with 3x64 features\n",
    "        for i, dat in enumerate(df.iterrows()):\n",
    "            index, row = dat\n",
    "            sample = dict()\n",
    "            if t_train is not None:\n",
    "                features = row.drop(['id', 'species', 'image'], axis=0).values\n",
    "            else:\n",
    "                features = row.drop(['id', 'image'], axis=0).values\n",
    "            sample['margin'] = features[:64]\n",
    "            sample['shape'] = features[64:128]\n",
    "            sample['texture'] = features[128:]\n",
    "            if t_train is not None:\n",
    "                sample['t'] = np.asarray(t_train[i], dtype='int32')\n",
    "            image = imread(row['image'], as_grey=True)\n",
    "            image = resize(image, output_shape=image_shape)\n",
    "            image = np.expand_dims(image, axis=2)\n",
    "            sample['image'] = image   \n",
    "            data[row['id']] = sample\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\t%d of %d\" % (i, len(df)))\n",
    "        return data\n",
    "\n",
    "    def _format_dataset(self, df, for_train):\n",
    "        # making arrays with all data in, is nessesary when doing validation split\n",
    "        data = dict()\n",
    "        value = list(df.values())[0]\n",
    "        img_tot_shp = tuple([len(df)] + list(value['image'].shape))\n",
    "        data['images'] = np.zeros(img_tot_shp, dtype='float32')\n",
    "        feature_tot_shp = (len(df), 64)\n",
    "        data['margins'] = np.zeros(feature_tot_shp, dtype='float32')\n",
    "        data['shapes'] = np.zeros(feature_tot_shp, dtype='float32')\n",
    "        data['textures'] = np.zeros(feature_tot_shp, dtype='float32')\n",
    "        if for_train:\n",
    "            data['ts'] = np.zeros((len(df),), dtype='int32')\n",
    "        else:\n",
    "            data['ids'] = np.zeros((len(df),), dtype='int32')\n",
    "        for i, pair in enumerate(df.items()):\n",
    "            key, value = pair\n",
    "            data['images'][i] = value['image']\n",
    "            data['margins'][i] = value['margin']\n",
    "            data['shapes'][i] = value['shape']\n",
    "            data['textures'][i] = value['texture']\n",
    "            if for_train:\n",
    "                data['ts'][i] = value['t']\n",
    "            else:\n",
    "                data['ids'][i] = key\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data ...\n",
      "loading train ...\n",
      "\t0 of 990\n",
      "\t100 of 990\n",
      "\t200 of 990\n",
      "\t300 of 990\n",
      "\t400 of 990\n",
      "\t500 of 990\n",
      "\t600 of 990\n",
      "\t700 of 990\n",
      "\t800 of 990\n",
      "\t900 of 990\n",
      "loading test ...\n",
      "\t0 of 594\n",
      "\t100 of 594\n",
      "\t200 of 594\n",
      "\t300 of 594\n",
      "\t400 of 594\n",
      "\t500 of 594\n",
      "data loaded\n",
      "@@@Shape checking of data sets@@@\n",
      "TRAIN\n",
      "\timages\t(990, 128, 128, 1)0.462174\n",
      "\tmargins\t(990, 64)\t0.015625\n",
      "\tshapes\t(990, 64)\t0.000607\n",
      "\ttextures(990, 64)\t0.015625\n",
      "\tts\t 990\n",
      "\twhile training, batch_generator will onehot encode ts to (batch_size, num_classes)\n",
      "TEST\n",
      "\timages\t(594, 128, 128, 1)\t0.463148\n",
      "\tmargins\t(594, 64)\t0.015625\n",
      "\tshapes\t(594, 64)\t0.000604\n",
      "\ttextures(594, 64)\t0.015625\n",
      "\tids\t594\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BASE_PATH = \"/Users/avickbiswas/DataScience/Kaggle/leaves\\ classification/\"\n",
    "TRAIN_PATH = \"train.csv\"\n",
    "TEST_PATH = \"test.csv\"\n",
    "IMAGE_PATHS = glob.glob(\"images/*.jpg\")\n",
    "NUM_CLASSES = 99\n",
    "IMAGE_SHAPE = (128, 128, 1)\n",
    "NUM_FEATURES = 64 # for all three features, margin, shape and texture\n",
    "# train holds both X (input) and t (target/truth)\n",
    "data = load_data(train_path=TRAIN_PATH, test_path=TEST_PATH,\n",
    "                 image_paths=IMAGE_PATHS, image_shape=IMAGE_SHAPE[:2])\n",
    "# to visualize the size of the dimensions of the data\n",
    "print\n",
    "print(\"@@@Shape checking of data sets@@@\")\n",
    "print\n",
    "print(\"TRAIN\")\n",
    "print(\"\\timages\\t%s%f\" % (data.train['images'].shape, data.train['images'].mean())) \n",
    "print(\"\\tmargins\\t%s\\t%f\" % (data.train['margins'].shape, data.train['margins'].mean()))\n",
    "print(\"\\tshapes\\t%s\\t%f\" % (data.train['shapes'].shape, data.train['shapes'].mean()))\n",
    "print(\"\\ttextures%s\\t%f\" % (data.train['textures'].shape, data.train['textures'].mean()))\n",
    "print(\"\\tts\\t %s\" % (data.train['ts'].shape))\n",
    "print(\"\\twhile training, batch_generator will onehot encode ts to (batch_size, num_classes)\")\n",
    "print\n",
    "print(\"TEST\")\n",
    "print(\"\\timages\\t%s\\t%f\" % (data.test['images'].shape, data.test['images'].mean()))\n",
    "print(\"\\tmargins\\t%s\\t%f\" % (data.test['margins'].shape, data.test['margins'].mean()))\n",
    "print(\"\\tshapes\\t%s\\t%f\" % (data.test['shapes'].shape, data.test['shapes'].mean()))\n",
    "print(\"\\ttextures%s\\t%f\" % (data.test['textures'].shape, data.test['textures'].mean()))\n",
    "print(\"\\tids\\t%s\" % (data.test['ids'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit as SSS\n",
    "\n",
    "class batch_generator():\n",
    "    def __init__(self, data, batch_size=64, num_classes=99,\n",
    "                 num_iterations=5e3, num_features=64, seed=42, val_size=0.1):\n",
    "        print(\"initiating batch generator\")\n",
    "        self._train = data.train\n",
    "        self._test = data.test\n",
    "        # get image size\n",
    "        value = self._train['images'][0]\n",
    "        self._image_shape = list(value.shape)\n",
    "        self._batch_size = batch_size\n",
    "        self._num_classes = num_classes\n",
    "        self._num_iterations = num_iterations\n",
    "        self._num_features = num_features\n",
    "        self._seed = seed\n",
    "        self._val_size = 0.1\n",
    "        self._valid_split()\n",
    "        print(\"batch generator initiated ...\")\n",
    "\n",
    "    def _valid_split(self):\n",
    "        self._idcs_train, self._idcs_valid = next(iter(\n",
    "            SSS(self._train['ts'], n_iter=1, test_size=self._val_size, random_state=self._seed)))\n",
    "        \n",
    "    def _shuffle_train(self):\n",
    "        np.random.shuffle(self._idcs_train)\n",
    "\n",
    "    def _batch_init(self, purpose):\n",
    "        assert purpose in ['train', 'valid', 'test']\n",
    "        batch_holder = dict()\n",
    "        batch_holder['margins'] = np.zeros((self._batch_size, self._num_features), dtype='float32')\n",
    "        batch_holder['shapes'] = np.zeros((self._batch_size, self._num_features), dtype='float32')\n",
    "        batch_holder['textures'] = np.zeros((self._batch_size, self._num_features), dtype='float32')\n",
    "        batch_holder['images'] = np.zeros(tuple([self._batch_size] + self._image_shape), dtype='float32')\n",
    "        if (purpose == \"train\") or (purpose == \"valid\"):\n",
    "            batch_holder['ts'] = np.zeros((self._batch_size, self._num_classes), dtype='float32')          \n",
    "        else:\n",
    "            batch_holder['ids'] = []\n",
    "        return batch_holder\n",
    "\n",
    "    def gen_valid(self):\n",
    "        batch = self._batch_init(purpose='train')\n",
    "        i = 0\n",
    "        for idx in self._idcs_valid:\n",
    "            batch['margins'][i] = self._train['margins'][idx]\n",
    "            batch['shapes'][i] = self._train['shapes'][idx]\n",
    "            batch['textures'][i] = self._train['textures'][idx]\n",
    "            batch['images'][i] = self._train['images'][idx]\n",
    "            batch['ts'][i] = onehot(np.asarray([self._train['ts'][idx]], dtype='float32'), self._num_classes)\n",
    "            i += 1\n",
    "            if i >= self._batch_size:\n",
    "                yield batch, i\n",
    "                batch = self._batch_init(purpose='valid')\n",
    "                i = 0\n",
    "        if i != 0:\n",
    "            yield batch, i\n",
    "\n",
    "    def gen_test(self):\n",
    "        batch = self._batch_init(purpose='test')\n",
    "        i = 0\n",
    "        for idx in range(len(self._test['ids'])):\n",
    "            batch['margins'][i] = self._test['margins'][idx]\n",
    "            batch['shapes'][i] = self._test['shapes'][idx]\n",
    "            batch['textures'][i] = self._test['textures'][idx]\n",
    "            batch['images'][i] = self._test['images'][idx]\n",
    "            batch['ids'].append(self._test['ids'][idx])\n",
    "            i += 1\n",
    "            if i >= self._batch_size:\n",
    "                yield batch, i\n",
    "                batch = self._batch_init(purpose='test')\n",
    "                i = 0\n",
    "        if i != 0:\n",
    "            yield batch, i\n",
    "            \n",
    "\n",
    "    def gen_train(self):\n",
    "        batch = self._batch_init(purpose='train')\n",
    "        iteration = 0\n",
    "        i = 0\n",
    "        while True:\n",
    "            # shuffling all batches\n",
    "            self._shuffle_train()\n",
    "            for idx in self._idcs_train:\n",
    "                # extract data from dict\n",
    "                batch['margins'][i] = self._train['margins'][idx]\n",
    "                batch['shapes'][i] = self._train['shapes'][idx]\n",
    "                batch['textures'][i] = self._train['textures'][idx]\n",
    "                batch['images'][i] = self._train['images'][idx]\n",
    "                batch['ts'][i] = onehot(np.asarray([self._train['ts'][idx]], dtype='float32'), self._num_classes)\n",
    "                i += 1\n",
    "                if i >= self._batch_size:\n",
    "                    yield batch\n",
    "                    batch = self._batch_init(purpose='train')\n",
    "                    i = 0\n",
    "                    iteration += 1\n",
    "                    if iteration >= self._num_iterations:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiating batch generator\n",
      "batch generator initiated ...\n",
      "@@@Shape/mean checking of batches@@@\n",
      "TRAIN\n",
      "\timages, (64, 128, 128, 1)\n",
      "\tmargins, (64, 64)\n",
      "\tshapes, (64, 64)\n",
      "\ttextures, (64, 64)\n",
      "\tts, (64, 99)\n",
      "VALID\n",
      "\timages, (64, 128, 128, 1)\n",
      "\tmargins, (64, 64)\n",
      "\tshapes, (64, 64)\n",
      "\ttextures, (64, 64)\n",
      "\tts, (64, 99)\n",
      "TEST\n",
      "\timages, (64, 128, 128, 1)\n",
      "\tmargins, (64, 64)\n",
      "\tshapes, (64, 64)\n",
      "\ttextures, (64, 64)\n",
      "\tids, 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avickbiswas/anaconda/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py:21: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "dummy_batch_gen = batch_generator(data, batch_size=64, num_classes=99, num_iterations=5e3, seed=42)\n",
    "train_batch = next(dummy_batch_gen.gen_train())\n",
    "valid_batch, i = next(dummy_batch_gen.gen_valid())\n",
    "test_batch, i = next(dummy_batch_gen.gen_test())\n",
    "\n",
    "print\n",
    "print(\"@@@Shape/mean checking of batches@@@\")\n",
    "print\n",
    "print(\"TRAIN\")\n",
    "print(\"\\timages,\", train_batch['images'].shape)\n",
    "print(\"\\tmargins,\", train_batch['margins'].shape)\n",
    "print(\"\\tshapes,\", train_batch['shapes'].shape)\n",
    "print(\"\\ttextures,\", train_batch['textures'].shape)\n",
    "print(\"\\tts,\", train_batch['ts'].shape)\n",
    "print\n",
    "print(\"VALID\")\n",
    "print(\"\\timages,\", valid_batch['images'].shape)\n",
    "print(\"\\tmargins,\", valid_batch['margins'].shape)\n",
    "print(\"\\tshapes,\", valid_batch['shapes'].shape)\n",
    "print(\"\\ttextures,\", valid_batch['textures'].shape)\n",
    "print(\"\\tts,\", valid_batch['ts'].shape)\n",
    "print\n",
    "print(\"TEST\")\n",
    "print(\"\\timages,\", test_batch['images'].shape)\n",
    "print(\"\\tmargins,\", test_batch['margins'].shape)\n",
    "print(\"\\tshapes,\", test_batch['shapes'].shape)\n",
    "print(\"\\ttextures,\", test_batch['textures'].shape)\n",
    "print(\"\\tids,\", len(test_batch['ids']))\n",
    "# notice that mean is very different, which is why we use batch_norm in all input data in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# contrib layers similar to wrappings used in Lasagne (for theano) or Keras\n",
    "from tensorflow.contrib.layers import fully_connected, convolution2d, flatten, batch_norm, max_pool2d, dropout\n",
    "from tensorflow.python.ops.nn import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from tensorflow.python.ops.nn import dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wrapping conv with batch_norm\n",
    "def conv(l_in, num_outputs, kernel_size, scope, stride=1):\n",
    "    return convolution2d(l_in, num_outputs=num_outputs, kernel_size=kernel_size,\n",
    "                         stride=stride, normalizer_fn=batch_norm, scope=scope)\n",
    "\n",
    "# pre-activation: http://arxiv.org/abs/1603.05027\n",
    "# wrapping convolutions and batch_norm\n",
    "def conv_pre(l_in, num_outputs, kernel_size, scope, stride=1):\n",
    "    l_norm = batch_norm(l_in)\n",
    "    l_relu = relu(l_norm)\n",
    "    return convolution2d(l_relu, num_outputs=num_outputs, kernel_size=kernel_size,\n",
    "                         stride=stride, activation_fn=None, scope=scope)\n",
    "# easy to use pool function\n",
    "def pool(l_in, scope, kernel_size=(3, 3)):\n",
    "    return max_pool2d(l_in, kernel_size=kernel_size, scope=scope) # (3, 3) has shown to work better than (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'features_bn/beta_summary:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'features_bn/moving_mean_summary:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'features_bn/moving_variance_summary:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'y/weights_summary:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'y/biases_summary:0' shape=() dtype=string>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperameters of the model\n",
    "height, width, channels = IMAGE_SHAPE\n",
    "# resetting the graph ...\n",
    "reset_default_graph()\n",
    "\n",
    "# Setting up placeholder, this is where your data enters the graph!\n",
    "x_image_pl = tf.placeholder(tf.float32, [None, height, width, channels], name=\"x_image_pl\")\n",
    "x_margin_pl = tf.placeholder(tf.float32, [None, NUM_FEATURES], name=\"x_margin_pl\")\n",
    "x_shape_pl = tf.placeholder(tf.float32, [None, NUM_FEATURES], name=\"x_shape_pl\")\n",
    "x_texture_pl = tf.placeholder(tf.float32, [None, NUM_FEATURES], name=\"x_texture_pl\")\n",
    "is_training_pl = tf.placeholder(tf.bool, name=\"is_training_pl\")\n",
    "\n",
    "# Building the layers of the neural network\n",
    "# we define the variable scope, so we more easily can recognise our variables later\n",
    "\n",
    "## IMAGE\n",
    "#l_conv1_a = conv(x_image_pl, 16, (5, 5), scope=\"l_conv1_a\")\n",
    "#l_pool1 = pool(l_conv1_a, scope=\"l_pool1\")\n",
    "#l_conv2_a = conv(l_pool1, 16, (5, 5), scope=\"l_conv2_a\")\n",
    "#l_pool2 = pool(l_conv2_a, scope=\"l_pool2\")\n",
    "#l_conv3_a = conv(l_pool2, 16, (5, 5), scope=\"l_conv3_a\")\n",
    "#l_pool3 = pool(l_conv3_a, scope=\"l_pool3\")\n",
    "#l_conv4_a = conv(l_pool3, 16, (5, 5), scope=\"l_conv4_a\")\n",
    "#l_pool4 = pool(l_conv3_a, scope=\"l_pool4\")\n",
    "#l_flatten = flatten(l_pool4, scope=\"flatten\")\n",
    "\n",
    "## RNN\n",
    "# define the cell of your RNN\n",
    "#shape_cell = tf.nn.rnn_cell.GRUCell(100)\n",
    "# run the RNN as outputs, state = tf.nn.dynamic_rnn(cell, ...)\n",
    "# given we run many-to-one we only care about the last state, so only\n",
    "# shape_state is defined\n",
    "#_, shape_state = tf.nn.dynamic_rnn(cell=shape_cell,\n",
    "#    inputs=tf.expand_dims(batch_norm(x_shape_pl), 2), dtype=tf.float32, scope=\"shape_rnn\")\n",
    "\n",
    "## COMBINE\n",
    "# use margin, shape and texture only\n",
    "features = tf.concat(concat_dim=1, values=[x_margin_pl, x_shape_pl, x_texture_pl], name=\"features\")\n",
    "# uncomment to use image only\n",
    "#features = l_flatten\n",
    "# uncomment to use margin, rnn_state on shape and texture only\n",
    "#features = tf.concat(concat_dim=1, values=[x_margin_pl, shape_state, x_texture_pl], name=\"features\")\n",
    "features = batch_norm(features, scope='features_bn')\n",
    "#l2 = fully_connected(features, num_outputs=256, activation_fn=relu,\n",
    "#                     normalizer_fn=batch_norm, scope=\"l2\")\n",
    "#l2 = dropout(l2, is_training=is_training_pl, scope=\"l2_dropout\")\n",
    "y = fully_connected(features, NUM_CLASSES, activation_fn=softmax, scope=\"y\")\n",
    "\n",
    "# add TensorBoard summaries for all variables\n",
    "tf.contrib.layers.summarize_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_image_pl, (?, 128, 128, 1)\n",
      "x_margin_pl, (?, 64)\n",
      "x_shape_pl, (?, 64)\n",
      "x_texture_pl, (?, 64)\n",
      "features, (?, 192)\n",
      "y, (?, 99)\n"
     ]
    }
   ],
   "source": [
    "# PRINT NETWORK (good practice to also include outcommented code when using it)\n",
    "\n",
    "print(\"x_image_pl,\", x_image_pl.get_shape())\n",
    "print(\"x_margin_pl,\", x_margin_pl.get_shape())\n",
    "print(\"x_shape_pl,\", x_shape_pl.get_shape())\n",
    "print(\"x_texture_pl,\", x_texture_pl.get_shape())\n",
    "print(\"features,\", features.get_shape())\n",
    "print(\"y,\", y.get_shape())\n",
    "\n",
    "# for the MLP\n",
    "#print \"l2,\", l2.get_shape()\n",
    "# for the RNN\n",
    "#print \"shape_state,\", shape_state.get_shape()\n",
    "# for the CNN\n",
    "#print \"l_conv1_a,\", l_conv1_a.get_shape()\n",
    "#...\n",
    "#print \"l_pool4,\", l_pool4.get_shape()\n",
    "#print \"l_flatten,\", l_flatten.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-56-bd0dc5ec1fdd>:45 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-56-bd0dc5ec1fdd>:46 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-56-bd0dc5ec1fdd>:47 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-56-bd0dc5ec1fdd>:48 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-56-bd0dc5ec1fdd>:49 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ScalarSummary_4:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_norm = 1\n",
    "# y_ is a placeholder variable taking on the value of the target batch.\n",
    "ts_pl = tf.placeholder(tf.float32, [None, NUM_CLASSES], name=\"targets_pl\")\n",
    "lr_pl = tf.placeholder(tf.float32, [], name=\"learning_rate_pl\")\n",
    "\n",
    "def loss_and_acc(preds):\n",
    "    # computing cross entropy per sample\n",
    "    cross_entropy = -tf.reduce_sum(ts_pl * tf.log(preds+1e-10), reduction_indices=[1])\n",
    "    # averaging over samples\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    # if you want regularization\n",
    "    #reg_scale = 0.0001\n",
    "    #regularize = tf.contrib.layers.l2_regularizer(reg_scale)\n",
    "    #params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    #reg_term = sum([regularize(param) for param in params])\n",
    "    #loss += reg_term\n",
    "    # calculate accuracy\n",
    "    argmax_y = tf.to_int32(tf.argmax(preds, dimension=1))\n",
    "    argmax_t = tf.to_int32(tf.argmax(ts_pl, dimension=1))\n",
    "    correct = tf.to_float(tf.equal(argmax_y, argmax_t))\n",
    "    accuracy = tf.reduce_mean(correct)\n",
    "    return loss, accuracy, argmax_y\n",
    "\n",
    "# loss, accuracy and prediction\n",
    "loss, accuracy, prediction = loss_and_acc(y)\n",
    "\n",
    "loss_valid = loss\n",
    "accuracy_valid = accuracy\n",
    "loss_valid, accuracy_valid, _ = loss_and_acc(y)\n",
    "\n",
    "# defining our optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "# applying the gradients\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "gradients, variables = zip(*grads_and_vars)  # unzip list of tuples\n",
    "clipped_gradients, global_norm = (\n",
    "    tf.clip_by_global_norm(gradients, clip_norm) )\n",
    "clipped_grads_and_vars = zip(clipped_gradients, variables)\n",
    "\n",
    "# make training op for applying the gradients\n",
    "train_op = optimizer.apply_gradients(clipped_grads_and_vars)\n",
    "\n",
    "# make tensorboard summeries\n",
    "tf.scalar_summary('train/global gradient norm', global_norm)\n",
    "tf.scalar_summary('train/loss', loss)\n",
    "tf.scalar_summary('train/accuracy', accuracy)\n",
    "tf.scalar_summary('validation/loss', loss_valid)\n",
    "tf.scalar_summary('validation/accuracy', accuracy_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y (45, 99)\n"
     ]
    }
   ],
   "source": [
    "#Test the forward pass\n",
    "_img_shape = tuple([45]+list(IMAGE_SHAPE))\n",
    "_feature_shape = (45, NUM_FEATURES)\n",
    "_x_image = np.random.normal(0, 1, _img_shape).astype('float32') #dummy data\n",
    "_x_margin = np.random.normal(0, 1, _feature_shape).astype('float32')\n",
    "_x_shape = np.random.normal(0, 1, _feature_shape).astype('float32')\n",
    "_x_texture = np.random.normal(0, 1, _feature_shape).astype('float32')\n",
    "\n",
    "# restricting memory usage, TensorFlow is greedy and will use all memory otherwise\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)\n",
    "# initialize the Session\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts))\n",
    "# test the forward pass\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {x_image_pl: _x_image,\n",
    "             x_margin_pl: _x_margin,\n",
    "             x_shape_pl: _x_shape,\n",
    "             x_texture_pl: _x_texture,\n",
    "             is_training_pl: False}\n",
    "res_forward_pass = sess.run(fetches=[y], feed_dict=feed_dict)\n",
    "print(\"y\", res_forward_pass[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiating batch generator\n",
      "batch generator initiated ...\n",
      "WARNING:tensorflow:From <ipython-input-62-4e34f1cdba98>:18 in <module>.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "\ttrain_loss \ttrain_acc \tvalid_loss \tvalid_acc\n",
      "0:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avickbiswas/anaconda/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py:21: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "200:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "300:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "400:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "500:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "600:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "700:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "800:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "900:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "1000:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "1100:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "1200:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "1300:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "1400:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "1500:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "1600:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "1700:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "1800:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "1900:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "2000:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "2100:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "2200:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "2300:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "2400:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "2500:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "2600:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "2700:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "2800:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "2900:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "3000:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "3100:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "3200:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "3300:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "3400:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "3500:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "3600:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "3700:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "3800:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "3900:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "4000:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "4100:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "4200:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "4300:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "4400:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "4500:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "4600:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "4700:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "4800:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "4900:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "5000:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "5100:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "5200:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "5300:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "5400:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "5500:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "5600:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "5700:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "5800:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "5900:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "6000:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "6100:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "6200:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "6300:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "6400:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "6500:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "6600:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "6700:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "6800:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "6900:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "7000:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "7100:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "7200:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "7300:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "7400:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "7500:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "7600:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "7700:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "7800:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "7900:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "8000:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "8100:\t  0.00\t\t  100.0\t\t  0.01\t\t  84.0\n",
      "8200:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "8300:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "8400:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "8500:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "8600:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "8700:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "8800:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "8900:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "9000:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "9100:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "9200:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "9300:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "9400:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "9500:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "9600:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "9700:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "9800:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n",
      "9900:\t  0.00\t\t  100.0\t\t  0.00\t\t  84.0\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "BATCH_SIZE = 64\n",
    "ITERATIONS = 1e4\n",
    "LOG_FREQ = 10\n",
    "VALIDATION_SIZE = 0.1 # 0.1 is ~ 100 samples for valition\n",
    "SEED = 42\n",
    "DROPOUT = False\n",
    "LEARNING_RATE = 0.0005\n",
    "VALID_EVERY = 100\n",
    "\n",
    "batch_gen = batch_generator(data, batch_size=BATCH_SIZE, num_classes=NUM_CLASSES,\n",
    "                            num_iterations=ITERATIONS, seed=SEED, val_size=VALIDATION_SIZE)\n",
    "\n",
    "# setup and write summaries\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "summaries_path = \"tensorboard/%s/logs\" % (timestamp)\n",
    "summaries = tf.summary.merge_all();#tf.merge_all_summaries()\n",
    "summarywriter = tf.train.SummaryWriter(summaries_path, sess.graph)\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "print(\"\\ttrain_loss \\ttrain_acc \\tvalid_loss \\tvalid_acc\")\n",
    "for i, batch_train in enumerate(batch_gen.gen_train()):\n",
    "    if i>=ITERATIONS:\n",
    "        break\n",
    "    fetches_train = [train_op, loss, accuracy, summaries]\n",
    "    feed_dict_train = {\n",
    "        x_image_pl: batch_train['images'],\n",
    "        x_margin_pl: batch_train['margins'],\n",
    "        x_shape_pl: batch_train['shapes'],\n",
    "        x_texture_pl: batch_train['textures'],\n",
    "        ts_pl: batch_train['ts'],\n",
    "        is_training_pl: DROPOUT,\n",
    "        lr_pl: LEARNING_RATE,\n",
    "        \n",
    "    }\n",
    "    res_train = sess.run(fetches=fetches_train, feed_dict=feed_dict_train)\n",
    "    if i % LOG_FREQ == 0:\n",
    "        summarywriter.add_summary(res_train[3], i)\n",
    "    train_loss.append(res_train[1])\n",
    "    train_acc.append(res_train[2])\n",
    "    \n",
    "    # validate\n",
    "    if i % VALID_EVERY == 0:\n",
    "        cur_acc = 0\n",
    "        cur_loss = 0\n",
    "        tot_num = 0\n",
    "        # batch validation\n",
    "        for batch_valid, num in batch_gen.gen_valid():\n",
    "            # fetches and feed_dict for validation\n",
    "            fetches_valid = [loss_valid, accuracy_valid, summaries]\n",
    "            feed_dict_valid = {\n",
    "                x_image_pl: batch_valid['images'],\n",
    "                x_margin_pl: batch_valid['margins'],\n",
    "                x_shape_pl: batch_valid['shapes'],\n",
    "                x_texture_pl: batch_valid['textures'],\n",
    "                ts_pl: batch_valid['ts'],\n",
    "                is_training_pl: False,\n",
    "            }\n",
    "            # run validation\n",
    "            res_valid = sess.run(fetches=fetches_valid, feed_dict=feed_dict_valid)\n",
    "            # tensorboard and costs\n",
    "            summarywriter.add_summary(res_valid[2], i)\n",
    "            cur_loss += res_valid[0]*num\n",
    "            cur_acc += res_valid[1]*num\n",
    "            tot_num += num\n",
    "        valid_loss = cur_loss / float(tot_num)\n",
    "        valid_acc = (cur_acc / float(tot_num)) * 100\n",
    "        train_loss = sum(train_loss) / float(len(train_loss))\n",
    "        train_acc = sum(train_acc) / float(len(train_acc)) * 100\n",
    "        print(\"%d:\\t  %.2f\\t\\t  %.1f\\t\\t  %.2f\\t\\t  %.1f\" % (i, train_loss, train_acc, valid_loss, valid_acc))\n",
    "        train_loss = []\n",
    "        train_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GET PREDICTIONS\n",
    "# containers to collect ids and predictions\n",
    "ids_test = []\n",
    "preds_test = []\n",
    "# run like with validation\n",
    "for batch_test, num in batch_gen.gen_test():\n",
    "    # fetching for test we only need y\n",
    "    fetches_test = [y]\n",
    "    # same as validation, but no batch['ts']\n",
    "    feed_dict_test = {\n",
    "        x_image_pl: batch_test['images'],\n",
    "        x_margin_pl: batch_test['margins'],\n",
    "        x_shape_pl: batch_test['shapes'],\n",
    "        x_texture_pl: batch_test['textures'],\n",
    "        is_training_pl: False\n",
    "    }\n",
    "    # get the result\n",
    "    res_test = sess.run(fetches=fetches_test, feed_dict=feed_dict_test)\n",
    "    y_out = res_test[0]\n",
    "    ids_test.append(batch_test['ids'])\n",
    "    if num!=len(y_out):\n",
    "        # in case of the last batch, num will be less than batch_size\n",
    "        y_out = y_out[:num]\n",
    "    preds_test.append(y_out)\n",
    "# concatenate it all, to form one list/array\n",
    "ids_test = list(itertools.chain.from_iterable(ids_test))\n",
    "preds_test = np.concatenate(preds_test, axis=0)\n",
    "assert len(ids_test) == len(preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>...</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1026</td>\n",
       "      <td>2.869020e-13</td>\n",
       "      <td>1.529277e-10</td>\n",
       "      <td>3.497055e-09</td>\n",
       "      <td>3.752200e-09</td>\n",
       "      <td>8.665882e-09</td>\n",
       "      <td>1.668734e-15</td>\n",
       "      <td>1.253632e-11</td>\n",
       "      <td>1.692365e-10</td>\n",
       "      <td>5.721615e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.268308e-14</td>\n",
       "      <td>9.879059e-07</td>\n",
       "      <td>5.018530e-12</td>\n",
       "      <td>3.757866e-09</td>\n",
       "      <td>6.097649e-06</td>\n",
       "      <td>1.296256e-09</td>\n",
       "      <td>3.317226e-14</td>\n",
       "      <td>6.300510e-06</td>\n",
       "      <td>4.647927e-09</td>\n",
       "      <td>5.881330e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.159570e-12</td>\n",
       "      <td>8.310549e-13</td>\n",
       "      <td>3.229270e-15</td>\n",
       "      <td>4.123330e-07</td>\n",
       "      <td>4.229517e-13</td>\n",
       "      <td>1.825746e-16</td>\n",
       "      <td>1.171082e-11</td>\n",
       "      <td>1.719328e-13</td>\n",
       "      <td>2.621086e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.097174e-14</td>\n",
       "      <td>1.478120e-08</td>\n",
       "      <td>2.576582e-12</td>\n",
       "      <td>1.178369e-13</td>\n",
       "      <td>6.354355e-10</td>\n",
       "      <td>4.283691e-14</td>\n",
       "      <td>1.008377e-15</td>\n",
       "      <td>1.131792e-14</td>\n",
       "      <td>2.047118e-13</td>\n",
       "      <td>6.398953e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1029</td>\n",
       "      <td>5.695827e-08</td>\n",
       "      <td>8.574796e-09</td>\n",
       "      <td>6.509347e-11</td>\n",
       "      <td>1.547787e-11</td>\n",
       "      <td>1.921026e-07</td>\n",
       "      <td>2.038853e-10</td>\n",
       "      <td>1.342976e-05</td>\n",
       "      <td>1.524260e-10</td>\n",
       "      <td>1.485938e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>8.604357e-02</td>\n",
       "      <td>1.091695e-08</td>\n",
       "      <td>1.416735e-04</td>\n",
       "      <td>5.031326e-08</td>\n",
       "      <td>2.656954e-05</td>\n",
       "      <td>4.285481e-06</td>\n",
       "      <td>9.209554e-03</td>\n",
       "      <td>1.420646e-08</td>\n",
       "      <td>1.433977e-08</td>\n",
       "      <td>2.518181e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3.855745e-13</td>\n",
       "      <td>6.281097e-12</td>\n",
       "      <td>1.426525e-11</td>\n",
       "      <td>1.040503e-09</td>\n",
       "      <td>1.433467e-10</td>\n",
       "      <td>2.495290e-12</td>\n",
       "      <td>8.599153e-09</td>\n",
       "      <td>1.126502e-11</td>\n",
       "      <td>9.465763e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065881e-13</td>\n",
       "      <td>1.152906e-12</td>\n",
       "      <td>6.107722e-13</td>\n",
       "      <td>7.608827e-13</td>\n",
       "      <td>2.042700e-13</td>\n",
       "      <td>6.974107e-09</td>\n",
       "      <td>2.163322e-13</td>\n",
       "      <td>1.269684e-09</td>\n",
       "      <td>3.280878e-13</td>\n",
       "      <td>1.685711e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6.289131e-11</td>\n",
       "      <td>9.998888e-01</td>\n",
       "      <td>9.492183e-11</td>\n",
       "      <td>4.485563e-10</td>\n",
       "      <td>6.429574e-05</td>\n",
       "      <td>5.592501e-09</td>\n",
       "      <td>2.558854e-11</td>\n",
       "      <td>7.623985e-07</td>\n",
       "      <td>1.593226e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>3.396650e-10</td>\n",
       "      <td>6.050024e-10</td>\n",
       "      <td>1.039362e-10</td>\n",
       "      <td>1.682971e-11</td>\n",
       "      <td>9.298544e-15</td>\n",
       "      <td>1.238260e-10</td>\n",
       "      <td>2.479792e-10</td>\n",
       "      <td>1.954589e-13</td>\n",
       "      <td>9.756926e-13</td>\n",
       "      <td>1.767668e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1035</td>\n",
       "      <td>1.818157e-11</td>\n",
       "      <td>6.863546e-09</td>\n",
       "      <td>2.173861e-09</td>\n",
       "      <td>4.438699e-08</td>\n",
       "      <td>2.217040e-10</td>\n",
       "      <td>5.321795e-09</td>\n",
       "      <td>8.048378e-13</td>\n",
       "      <td>7.392057e-14</td>\n",
       "      <td>1.955893e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.699236e-13</td>\n",
       "      <td>6.840367e-11</td>\n",
       "      <td>4.944857e-11</td>\n",
       "      <td>2.903605e-12</td>\n",
       "      <td>1.078269e-11</td>\n",
       "      <td>1.067115e-10</td>\n",
       "      <td>5.698240e-11</td>\n",
       "      <td>1.130901e-09</td>\n",
       "      <td>1.218257e-08</td>\n",
       "      <td>1.763703e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>1.134462e-14</td>\n",
       "      <td>5.331436e-07</td>\n",
       "      <td>4.497413e-11</td>\n",
       "      <td>1.467479e-13</td>\n",
       "      <td>4.536607e-10</td>\n",
       "      <td>8.801194e-14</td>\n",
       "      <td>1.253105e-07</td>\n",
       "      <td>8.469607e-12</td>\n",
       "      <td>9.058447e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.105444e-11</td>\n",
       "      <td>1.528023e-12</td>\n",
       "      <td>1.819910e-09</td>\n",
       "      <td>1.115343e-11</td>\n",
       "      <td>4.180719e-11</td>\n",
       "      <td>1.226446e-08</td>\n",
       "      <td>1.039584e-04</td>\n",
       "      <td>1.779851e-10</td>\n",
       "      <td>4.638010e-10</td>\n",
       "      <td>1.362704e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>4.846606e-12</td>\n",
       "      <td>2.529955e-11</td>\n",
       "      <td>1.497237e-14</td>\n",
       "      <td>2.621346e-14</td>\n",
       "      <td>1.929146e-11</td>\n",
       "      <td>4.638825e-16</td>\n",
       "      <td>5.184325e-10</td>\n",
       "      <td>8.176667e-13</td>\n",
       "      <td>6.479242e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.929581e-10</td>\n",
       "      <td>2.864881e-13</td>\n",
       "      <td>3.057113e-08</td>\n",
       "      <td>2.215729e-11</td>\n",
       "      <td>7.997122e-08</td>\n",
       "      <td>2.561640e-09</td>\n",
       "      <td>2.334679e-07</td>\n",
       "      <td>8.070605e-10</td>\n",
       "      <td>4.601576e-12</td>\n",
       "      <td>1.653976e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1038</td>\n",
       "      <td>2.175138e-08</td>\n",
       "      <td>5.019227e-11</td>\n",
       "      <td>2.582438e-07</td>\n",
       "      <td>3.543059e-05</td>\n",
       "      <td>8.564473e-13</td>\n",
       "      <td>7.389378e-07</td>\n",
       "      <td>6.726415e-08</td>\n",
       "      <td>1.746448e-13</td>\n",
       "      <td>1.388468e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>4.369506e-11</td>\n",
       "      <td>2.025135e-13</td>\n",
       "      <td>1.079750e-10</td>\n",
       "      <td>1.002365e-11</td>\n",
       "      <td>6.731412e-14</td>\n",
       "      <td>2.736050e-09</td>\n",
       "      <td>1.360797e-13</td>\n",
       "      <td>2.705563e-15</td>\n",
       "      <td>3.459092e-10</td>\n",
       "      <td>4.684759e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>1.413082e-08</td>\n",
       "      <td>7.833825e-10</td>\n",
       "      <td>8.155917e-10</td>\n",
       "      <td>9.796035e-01</td>\n",
       "      <td>4.727880e-09</td>\n",
       "      <td>2.875598e-11</td>\n",
       "      <td>3.462835e-08</td>\n",
       "      <td>3.312818e-06</td>\n",
       "      <td>9.231528e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.673009e-06</td>\n",
       "      <td>1.388219e-07</td>\n",
       "      <td>7.266534e-08</td>\n",
       "      <td>1.893304e-07</td>\n",
       "      <td>4.795458e-06</td>\n",
       "      <td>5.396638e-06</td>\n",
       "      <td>8.016678e-10</td>\n",
       "      <td>1.999327e-09</td>\n",
       "      <td>5.937847e-06</td>\n",
       "      <td>6.150653e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>3.960769e-09</td>\n",
       "      <td>2.219355e-09</td>\n",
       "      <td>3.757949e-10</td>\n",
       "      <td>9.999495e-01</td>\n",
       "      <td>3.095623e-10</td>\n",
       "      <td>6.068299e-12</td>\n",
       "      <td>5.211927e-09</td>\n",
       "      <td>6.510664e-10</td>\n",
       "      <td>2.638876e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>4.305484e-11</td>\n",
       "      <td>8.346717e-09</td>\n",
       "      <td>3.677640e-09</td>\n",
       "      <td>3.945712e-09</td>\n",
       "      <td>7.765190e-08</td>\n",
       "      <td>2.066146e-06</td>\n",
       "      <td>9.740824e-12</td>\n",
       "      <td>1.570086e-09</td>\n",
       "      <td>6.575967e-08</td>\n",
       "      <td>2.098754e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1044</td>\n",
       "      <td>4.401027e-11</td>\n",
       "      <td>4.745763e-08</td>\n",
       "      <td>7.966423e-14</td>\n",
       "      <td>6.235737e-12</td>\n",
       "      <td>1.054721e-10</td>\n",
       "      <td>1.982366e-12</td>\n",
       "      <td>1.291552e-10</td>\n",
       "      <td>2.585980e-09</td>\n",
       "      <td>1.233317e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.589716e-12</td>\n",
       "      <td>4.071024e-14</td>\n",
       "      <td>8.526528e-08</td>\n",
       "      <td>1.205601e-13</td>\n",
       "      <td>2.838558e-12</td>\n",
       "      <td>1.024325e-09</td>\n",
       "      <td>1.220956e-07</td>\n",
       "      <td>4.031406e-11</td>\n",
       "      <td>8.599151e-13</td>\n",
       "      <td>2.292317e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1045</td>\n",
       "      <td>3.417634e-07</td>\n",
       "      <td>3.205540e-11</td>\n",
       "      <td>1.112152e-10</td>\n",
       "      <td>5.972434e-08</td>\n",
       "      <td>3.802777e-10</td>\n",
       "      <td>1.330715e-12</td>\n",
       "      <td>1.175176e-09</td>\n",
       "      <td>2.202643e-10</td>\n",
       "      <td>4.700801e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>3.024813e-11</td>\n",
       "      <td>4.622029e-11</td>\n",
       "      <td>1.799297e-06</td>\n",
       "      <td>1.234780e-08</td>\n",
       "      <td>2.315443e-06</td>\n",
       "      <td>8.428933e-10</td>\n",
       "      <td>5.190981e-11</td>\n",
       "      <td>5.744465e-12</td>\n",
       "      <td>2.439979e-09</td>\n",
       "      <td>1.518916e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23</td>\n",
       "      <td>1.370218e-14</td>\n",
       "      <td>1.537371e-08</td>\n",
       "      <td>4.375985e-10</td>\n",
       "      <td>8.760763e-09</td>\n",
       "      <td>4.705908e-10</td>\n",
       "      <td>3.299784e-07</td>\n",
       "      <td>5.521857e-09</td>\n",
       "      <td>1.752096e-13</td>\n",
       "      <td>2.018483e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.822858e-12</td>\n",
       "      <td>7.754210e-12</td>\n",
       "      <td>3.424814e-13</td>\n",
       "      <td>2.707355e-13</td>\n",
       "      <td>1.114967e-09</td>\n",
       "      <td>3.281941e-13</td>\n",
       "      <td>4.509813e-15</td>\n",
       "      <td>1.982658e-11</td>\n",
       "      <td>1.023958e-11</td>\n",
       "      <td>1.794373e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24</td>\n",
       "      <td>3.137803e-09</td>\n",
       "      <td>1.888337e-10</td>\n",
       "      <td>2.719570e-12</td>\n",
       "      <td>8.186363e-15</td>\n",
       "      <td>7.641454e-11</td>\n",
       "      <td>3.272528e-09</td>\n",
       "      <td>1.382859e-08</td>\n",
       "      <td>4.267509e-11</td>\n",
       "      <td>1.148087e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.292301e-12</td>\n",
       "      <td>4.817293e-14</td>\n",
       "      <td>1.461676e-13</td>\n",
       "      <td>4.840254e-10</td>\n",
       "      <td>1.055768e-13</td>\n",
       "      <td>5.479237e-14</td>\n",
       "      <td>5.008979e-15</td>\n",
       "      <td>5.013352e-17</td>\n",
       "      <td>4.756175e-15</td>\n",
       "      <td>2.124232e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1028</td>\n",
       "      <td>4.535547e-13</td>\n",
       "      <td>7.198407e-13</td>\n",
       "      <td>7.875701e-12</td>\n",
       "      <td>3.723646e-12</td>\n",
       "      <td>4.529923e-11</td>\n",
       "      <td>6.251595e-12</td>\n",
       "      <td>5.565679e-10</td>\n",
       "      <td>5.415494e-13</td>\n",
       "      <td>7.816946e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>6.928958e-12</td>\n",
       "      <td>2.818562e-08</td>\n",
       "      <td>4.127446e-11</td>\n",
       "      <td>3.180722e-09</td>\n",
       "      <td>1.793761e-09</td>\n",
       "      <td>8.041601e-11</td>\n",
       "      <td>1.960803e-11</td>\n",
       "      <td>1.759034e-11</td>\n",
       "      <td>7.883532e-12</td>\n",
       "      <td>2.923086e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1050</td>\n",
       "      <td>2.818978e-20</td>\n",
       "      <td>2.630064e-12</td>\n",
       "      <td>4.656703e-14</td>\n",
       "      <td>5.067191e-13</td>\n",
       "      <td>1.659925e-12</td>\n",
       "      <td>1.387737e-08</td>\n",
       "      <td>3.407821e-10</td>\n",
       "      <td>5.075782e-16</td>\n",
       "      <td>5.293439e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.455725e-16</td>\n",
       "      <td>3.861079e-18</td>\n",
       "      <td>1.299239e-17</td>\n",
       "      <td>3.698943e-17</td>\n",
       "      <td>9.800023e-19</td>\n",
       "      <td>2.130848e-14</td>\n",
       "      <td>1.293216e-18</td>\n",
       "      <td>4.190189e-17</td>\n",
       "      <td>2.199124e-15</td>\n",
       "      <td>2.329780e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28</td>\n",
       "      <td>4.247049e-07</td>\n",
       "      <td>2.558298e-08</td>\n",
       "      <td>7.113322e-11</td>\n",
       "      <td>2.566211e-11</td>\n",
       "      <td>9.556316e-11</td>\n",
       "      <td>3.339005e-12</td>\n",
       "      <td>4.481532e-09</td>\n",
       "      <td>1.576862e-07</td>\n",
       "      <td>9.999981e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.559344e-09</td>\n",
       "      <td>1.797289e-10</td>\n",
       "      <td>2.448060e-08</td>\n",
       "      <td>5.513813e-11</td>\n",
       "      <td>7.768745e-10</td>\n",
       "      <td>5.751609e-07</td>\n",
       "      <td>2.145429e-09</td>\n",
       "      <td>3.217214e-16</td>\n",
       "      <td>2.655700e-13</td>\n",
       "      <td>3.308940e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1053</td>\n",
       "      <td>1.060605e-12</td>\n",
       "      <td>9.325956e-11</td>\n",
       "      <td>5.856270e-08</td>\n",
       "      <td>5.153778e-12</td>\n",
       "      <td>2.054121e-12</td>\n",
       "      <td>1.098207e-08</td>\n",
       "      <td>2.126693e-07</td>\n",
       "      <td>3.803406e-12</td>\n",
       "      <td>1.811211e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>6.530509e-13</td>\n",
       "      <td>3.297032e-13</td>\n",
       "      <td>5.788538e-12</td>\n",
       "      <td>1.120405e-13</td>\n",
       "      <td>1.074327e-16</td>\n",
       "      <td>1.688173e-12</td>\n",
       "      <td>5.972809e-16</td>\n",
       "      <td>1.322741e-16</td>\n",
       "      <td>1.447215e-13</td>\n",
       "      <td>2.120400e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1054</td>\n",
       "      <td>4.746386e-09</td>\n",
       "      <td>1.232027e-14</td>\n",
       "      <td>1.104532e-16</td>\n",
       "      <td>9.782500e-12</td>\n",
       "      <td>1.155418e-11</td>\n",
       "      <td>7.653384e-16</td>\n",
       "      <td>1.726814e-18</td>\n",
       "      <td>1.290281e-07</td>\n",
       "      <td>3.847565e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>8.733175e-08</td>\n",
       "      <td>1.627425e-15</td>\n",
       "      <td>1.915426e-12</td>\n",
       "      <td>4.875493e-10</td>\n",
       "      <td>6.133196e-09</td>\n",
       "      <td>1.135355e-15</td>\n",
       "      <td>4.073993e-10</td>\n",
       "      <td>6.183092e-16</td>\n",
       "      <td>6.411148e-14</td>\n",
       "      <td>8.590073e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1055</td>\n",
       "      <td>4.622022e-06</td>\n",
       "      <td>3.410553e-11</td>\n",
       "      <td>7.467886e-18</td>\n",
       "      <td>2.352242e-03</td>\n",
       "      <td>6.147090e-10</td>\n",
       "      <td>1.491406e-13</td>\n",
       "      <td>1.812504e-13</td>\n",
       "      <td>1.095042e-06</td>\n",
       "      <td>2.422826e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>9.975854e-01</td>\n",
       "      <td>1.727756e-10</td>\n",
       "      <td>9.244686e-09</td>\n",
       "      <td>6.319249e-11</td>\n",
       "      <td>2.609683e-05</td>\n",
       "      <td>1.349412e-06</td>\n",
       "      <td>2.333383e-09</td>\n",
       "      <td>3.421780e-15</td>\n",
       "      <td>2.285414e-14</td>\n",
       "      <td>2.138086e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1433</td>\n",
       "      <td>1.181753e-13</td>\n",
       "      <td>4.109146e-09</td>\n",
       "      <td>1.150503e-07</td>\n",
       "      <td>5.023456e-09</td>\n",
       "      <td>7.432354e-11</td>\n",
       "      <td>6.742432e-04</td>\n",
       "      <td>1.463427e-08</td>\n",
       "      <td>2.840008e-14</td>\n",
       "      <td>2.410637e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>9.206077e-12</td>\n",
       "      <td>8.509545e-14</td>\n",
       "      <td>3.019739e-13</td>\n",
       "      <td>1.251737e-13</td>\n",
       "      <td>1.445862e-12</td>\n",
       "      <td>9.297333e-14</td>\n",
       "      <td>3.845387e-12</td>\n",
       "      <td>1.421198e-10</td>\n",
       "      <td>1.048826e-09</td>\n",
       "      <td>2.575307e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>1.641425e-11</td>\n",
       "      <td>4.558042e-14</td>\n",
       "      <td>3.473244e-09</td>\n",
       "      <td>1.102278e-08</td>\n",
       "      <td>1.645965e-10</td>\n",
       "      <td>9.056058e-10</td>\n",
       "      <td>6.901028e-11</td>\n",
       "      <td>4.331193e-14</td>\n",
       "      <td>2.566565e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.941523e-10</td>\n",
       "      <td>2.010456e-11</td>\n",
       "      <td>1.594813e-10</td>\n",
       "      <td>1.603333e-08</td>\n",
       "      <td>1.294943e-10</td>\n",
       "      <td>3.692892e-17</td>\n",
       "      <td>8.971643e-10</td>\n",
       "      <td>6.487788e-06</td>\n",
       "      <td>3.817768e-05</td>\n",
       "      <td>3.845432e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1058</td>\n",
       "      <td>4.192449e-08</td>\n",
       "      <td>1.971057e-08</td>\n",
       "      <td>7.537960e-11</td>\n",
       "      <td>8.589738e-12</td>\n",
       "      <td>1.132016e-09</td>\n",
       "      <td>1.430063e-11</td>\n",
       "      <td>6.161581e-11</td>\n",
       "      <td>9.824262e-01</td>\n",
       "      <td>1.288592e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.672771e-05</td>\n",
       "      <td>2.333090e-11</td>\n",
       "      <td>6.816097e-08</td>\n",
       "      <td>1.628511e-05</td>\n",
       "      <td>1.425376e-11</td>\n",
       "      <td>2.764155e-07</td>\n",
       "      <td>2.121873e-05</td>\n",
       "      <td>4.059649e-16</td>\n",
       "      <td>1.439874e-12</td>\n",
       "      <td>4.855786e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1371</td>\n",
       "      <td>1.096633e-08</td>\n",
       "      <td>3.420712e-11</td>\n",
       "      <td>1.889570e-13</td>\n",
       "      <td>1.219096e-08</td>\n",
       "      <td>1.000394e-09</td>\n",
       "      <td>2.623050e-12</td>\n",
       "      <td>7.360843e-13</td>\n",
       "      <td>3.324607e-10</td>\n",
       "      <td>6.311306e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>9.633766e-14</td>\n",
       "      <td>1.515068e-15</td>\n",
       "      <td>1.660768e-07</td>\n",
       "      <td>7.292880e-14</td>\n",
       "      <td>3.841548e-09</td>\n",
       "      <td>4.747549e-11</td>\n",
       "      <td>5.632530e-12</td>\n",
       "      <td>1.397190e-11</td>\n",
       "      <td>7.461164e-12</td>\n",
       "      <td>1.244433e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>36</td>\n",
       "      <td>5.914503e-08</td>\n",
       "      <td>2.544547e-13</td>\n",
       "      <td>5.241738e-12</td>\n",
       "      <td>1.316688e-14</td>\n",
       "      <td>1.118781e-10</td>\n",
       "      <td>2.130657e-12</td>\n",
       "      <td>1.741330e-13</td>\n",
       "      <td>1.742575e-11</td>\n",
       "      <td>1.533813e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.519011e-15</td>\n",
       "      <td>5.147142e-16</td>\n",
       "      <td>7.473930e-10</td>\n",
       "      <td>7.190707e-14</td>\n",
       "      <td>1.218199e-11</td>\n",
       "      <td>1.254371e-15</td>\n",
       "      <td>2.665548e-13</td>\n",
       "      <td>2.764684e-12</td>\n",
       "      <td>4.397991e-13</td>\n",
       "      <td>2.387567e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1542</td>\n",
       "      <td>1.403831e-05</td>\n",
       "      <td>2.174655e-10</td>\n",
       "      <td>2.638926e-11</td>\n",
       "      <td>1.432329e-06</td>\n",
       "      <td>1.416380e-09</td>\n",
       "      <td>2.185880e-12</td>\n",
       "      <td>4.386292e-10</td>\n",
       "      <td>2.055705e-09</td>\n",
       "      <td>1.826604e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.482801e-09</td>\n",
       "      <td>4.308499e-10</td>\n",
       "      <td>8.177479e-07</td>\n",
       "      <td>6.525383e-09</td>\n",
       "      <td>3.832788e-05</td>\n",
       "      <td>1.643768e-10</td>\n",
       "      <td>3.859595e-10</td>\n",
       "      <td>8.484144e-12</td>\n",
       "      <td>3.029612e-09</td>\n",
       "      <td>1.212928e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39</td>\n",
       "      <td>1.926356e-09</td>\n",
       "      <td>4.266883e-17</td>\n",
       "      <td>1.594544e-11</td>\n",
       "      <td>4.427570e-11</td>\n",
       "      <td>1.888961e-15</td>\n",
       "      <td>1.004494e-13</td>\n",
       "      <td>2.145729e-16</td>\n",
       "      <td>1.053228e-14</td>\n",
       "      <td>1.074267e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.193598e-11</td>\n",
       "      <td>2.776112e-09</td>\n",
       "      <td>1.205791e-16</td>\n",
       "      <td>1.143935e-09</td>\n",
       "      <td>1.013255e-13</td>\n",
       "      <td>5.976735e-16</td>\n",
       "      <td>1.734955e-16</td>\n",
       "      <td>4.099796e-11</td>\n",
       "      <td>9.197889e-11</td>\n",
       "      <td>6.522774e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1064</td>\n",
       "      <td>4.361836e-15</td>\n",
       "      <td>3.564977e-13</td>\n",
       "      <td>9.143995e-14</td>\n",
       "      <td>1.159072e-08</td>\n",
       "      <td>8.589051e-11</td>\n",
       "      <td>6.796306e-13</td>\n",
       "      <td>2.494278e-12</td>\n",
       "      <td>5.706887e-13</td>\n",
       "      <td>6.558697e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.723864e-13</td>\n",
       "      <td>2.687968e-10</td>\n",
       "      <td>5.204750e-13</td>\n",
       "      <td>3.046539e-15</td>\n",
       "      <td>1.488609e-09</td>\n",
       "      <td>1.898028e-09</td>\n",
       "      <td>1.333933e-15</td>\n",
       "      <td>3.535191e-09</td>\n",
       "      <td>3.030722e-12</td>\n",
       "      <td>7.498612e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>41</td>\n",
       "      <td>3.682360e-11</td>\n",
       "      <td>2.998908e-12</td>\n",
       "      <td>1.622214e-07</td>\n",
       "      <td>2.369039e-09</td>\n",
       "      <td>4.296188e-12</td>\n",
       "      <td>1.227473e-11</td>\n",
       "      <td>4.562128e-11</td>\n",
       "      <td>1.615422e-11</td>\n",
       "      <td>7.279345e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.786440e-10</td>\n",
       "      <td>2.645171e-11</td>\n",
       "      <td>1.522006e-13</td>\n",
       "      <td>1.227608e-08</td>\n",
       "      <td>7.384722e-12</td>\n",
       "      <td>4.432539e-06</td>\n",
       "      <td>7.984902e-14</td>\n",
       "      <td>2.508790e-16</td>\n",
       "      <td>4.366366e-12</td>\n",
       "      <td>1.075103e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>953</td>\n",
       "      <td>2.023934e-15</td>\n",
       "      <td>2.573280e-09</td>\n",
       "      <td>2.556793e-09</td>\n",
       "      <td>1.771523e-08</td>\n",
       "      <td>6.003354e-10</td>\n",
       "      <td>9.288937e-11</td>\n",
       "      <td>1.525636e-07</td>\n",
       "      <td>1.230931e-11</td>\n",
       "      <td>1.388125e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.970403e-10</td>\n",
       "      <td>5.689527e-09</td>\n",
       "      <td>2.491832e-12</td>\n",
       "      <td>1.132712e-07</td>\n",
       "      <td>1.653039e-09</td>\n",
       "      <td>8.393832e-09</td>\n",
       "      <td>8.442339e-09</td>\n",
       "      <td>1.094370e-05</td>\n",
       "      <td>3.648587e-07</td>\n",
       "      <td>4.278555e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1183</td>\n",
       "      <td>3.414820e-09</td>\n",
       "      <td>2.740715e-09</td>\n",
       "      <td>4.280774e-02</td>\n",
       "      <td>7.448633e-08</td>\n",
       "      <td>7.336368e-09</td>\n",
       "      <td>4.075376e-08</td>\n",
       "      <td>4.550176e-08</td>\n",
       "      <td>1.910461e-09</td>\n",
       "      <td>7.577875e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>7.062905e-10</td>\n",
       "      <td>8.729872e-08</td>\n",
       "      <td>3.120578e-12</td>\n",
       "      <td>2.561588e-07</td>\n",
       "      <td>7.937396e-12</td>\n",
       "      <td>9.878034e-06</td>\n",
       "      <td>1.058862e-11</td>\n",
       "      <td>3.174023e-11</td>\n",
       "      <td>4.702815e-08</td>\n",
       "      <td>1.509644e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>957</td>\n",
       "      <td>9.026579e-12</td>\n",
       "      <td>1.004403e-09</td>\n",
       "      <td>1.953264e-08</td>\n",
       "      <td>1.944490e-16</td>\n",
       "      <td>2.110981e-09</td>\n",
       "      <td>4.424295e-07</td>\n",
       "      <td>3.198239e-09</td>\n",
       "      <td>6.985671e-14</td>\n",
       "      <td>7.759068e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.994141e-12</td>\n",
       "      <td>1.907357e-12</td>\n",
       "      <td>3.925019e-13</td>\n",
       "      <td>3.458607e-10</td>\n",
       "      <td>1.327410e-14</td>\n",
       "      <td>1.414658e-14</td>\n",
       "      <td>1.921762e-13</td>\n",
       "      <td>4.466084e-17</td>\n",
       "      <td>6.552594e-12</td>\n",
       "      <td>7.014383e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>964</td>\n",
       "      <td>7.954026e-14</td>\n",
       "      <td>1.242175e-19</td>\n",
       "      <td>1.947626e-12</td>\n",
       "      <td>7.756982e-13</td>\n",
       "      <td>4.860622e-14</td>\n",
       "      <td>6.312200e-15</td>\n",
       "      <td>8.795291e-18</td>\n",
       "      <td>9.181437e-21</td>\n",
       "      <td>4.228698e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>6.378516e-13</td>\n",
       "      <td>1.516194e-12</td>\n",
       "      <td>3.393554e-13</td>\n",
       "      <td>1.671330e-10</td>\n",
       "      <td>8.078315e-10</td>\n",
       "      <td>4.867039e-23</td>\n",
       "      <td>1.085370e-12</td>\n",
       "      <td>2.433580e-05</td>\n",
       "      <td>1.512051e-06</td>\n",
       "      <td>9.616634e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>965</td>\n",
       "      <td>6.022441e-17</td>\n",
       "      <td>2.071268e-10</td>\n",
       "      <td>8.627926e-11</td>\n",
       "      <td>7.136986e-13</td>\n",
       "      <td>1.129920e-09</td>\n",
       "      <td>1.908611e-10</td>\n",
       "      <td>9.999728e-01</td>\n",
       "      <td>1.250714e-11</td>\n",
       "      <td>1.191870e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.462782e-11</td>\n",
       "      <td>1.251153e-10</td>\n",
       "      <td>3.342492e-14</td>\n",
       "      <td>3.734351e-09</td>\n",
       "      <td>2.536342e-11</td>\n",
       "      <td>3.010827e-10</td>\n",
       "      <td>3.156212e-13</td>\n",
       "      <td>3.292189e-11</td>\n",
       "      <td>1.061628e-13</td>\n",
       "      <td>6.805103e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>967</td>\n",
       "      <td>6.826291e-10</td>\n",
       "      <td>1.685481e-08</td>\n",
       "      <td>9.927867e-12</td>\n",
       "      <td>3.237670e-13</td>\n",
       "      <td>9.152659e-09</td>\n",
       "      <td>6.406066e-07</td>\n",
       "      <td>1.319785e-05</td>\n",
       "      <td>2.428501e-12</td>\n",
       "      <td>2.580002e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>3.116250e-10</td>\n",
       "      <td>1.183391e-09</td>\n",
       "      <td>2.098204e-11</td>\n",
       "      <td>2.459242e-08</td>\n",
       "      <td>1.507103e-08</td>\n",
       "      <td>6.702275e-12</td>\n",
       "      <td>4.888084e-11</td>\n",
       "      <td>5.657998e-13</td>\n",
       "      <td>1.885649e-12</td>\n",
       "      <td>7.580645e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>973</td>\n",
       "      <td>8.771042e-12</td>\n",
       "      <td>1.167048e-10</td>\n",
       "      <td>2.054995e-10</td>\n",
       "      <td>1.230446e-12</td>\n",
       "      <td>1.330633e-08</td>\n",
       "      <td>5.357805e-07</td>\n",
       "      <td>2.054533e-07</td>\n",
       "      <td>1.650111e-10</td>\n",
       "      <td>3.260041e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.639530e-11</td>\n",
       "      <td>4.196896e-09</td>\n",
       "      <td>2.848672e-11</td>\n",
       "      <td>1.389929e-08</td>\n",
       "      <td>1.109116e-09</td>\n",
       "      <td>2.873393e-10</td>\n",
       "      <td>1.533482e-10</td>\n",
       "      <td>5.922913e-11</td>\n",
       "      <td>1.708045e-11</td>\n",
       "      <td>2.830382e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>974</td>\n",
       "      <td>2.671925e-12</td>\n",
       "      <td>1.015591e-12</td>\n",
       "      <td>1.327866e-11</td>\n",
       "      <td>1.464944e-11</td>\n",
       "      <td>6.631848e-12</td>\n",
       "      <td>3.502573e-12</td>\n",
       "      <td>1.478311e-11</td>\n",
       "      <td>1.312714e-12</td>\n",
       "      <td>2.989797e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>2.853260e-11</td>\n",
       "      <td>4.170106e-09</td>\n",
       "      <td>2.073386e-12</td>\n",
       "      <td>1.851764e-11</td>\n",
       "      <td>1.721952e-09</td>\n",
       "      <td>4.940948e-11</td>\n",
       "      <td>8.207446e-11</td>\n",
       "      <td>3.214864e-13</td>\n",
       "      <td>3.870720e-13</td>\n",
       "      <td>2.593558e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>1215</td>\n",
       "      <td>8.547384e-13</td>\n",
       "      <td>2.068049e-13</td>\n",
       "      <td>5.888669e-10</td>\n",
       "      <td>5.485423e-13</td>\n",
       "      <td>3.155728e-08</td>\n",
       "      <td>1.094599e-06</td>\n",
       "      <td>1.146347e-14</td>\n",
       "      <td>4.458010e-13</td>\n",
       "      <td>4.214816e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.269145e-09</td>\n",
       "      <td>2.770870e-11</td>\n",
       "      <td>1.823678e-11</td>\n",
       "      <td>4.726436e-07</td>\n",
       "      <td>3.718997e-11</td>\n",
       "      <td>4.700438e-14</td>\n",
       "      <td>2.437842e-08</td>\n",
       "      <td>2.505690e-07</td>\n",
       "      <td>3.659023e-10</td>\n",
       "      <td>3.606462e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>977</td>\n",
       "      <td>2.457296e-14</td>\n",
       "      <td>1.245406e-10</td>\n",
       "      <td>3.219755e-08</td>\n",
       "      <td>3.469443e-14</td>\n",
       "      <td>4.705889e-11</td>\n",
       "      <td>9.993191e-01</td>\n",
       "      <td>6.881924e-10</td>\n",
       "      <td>1.549067e-14</td>\n",
       "      <td>5.842826e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>3.653523e-12</td>\n",
       "      <td>1.319033e-16</td>\n",
       "      <td>2.070559e-16</td>\n",
       "      <td>6.724311e-14</td>\n",
       "      <td>1.023536e-16</td>\n",
       "      <td>2.370604e-13</td>\n",
       "      <td>6.603811e-16</td>\n",
       "      <td>4.019022e-15</td>\n",
       "      <td>1.240068e-14</td>\n",
       "      <td>3.929130e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>980</td>\n",
       "      <td>7.581440e-15</td>\n",
       "      <td>6.880232e-17</td>\n",
       "      <td>7.398001e-13</td>\n",
       "      <td>1.617897e-17</td>\n",
       "      <td>1.615814e-12</td>\n",
       "      <td>7.607419e-17</td>\n",
       "      <td>1.779332e-19</td>\n",
       "      <td>8.421961e-17</td>\n",
       "      <td>1.167653e-20</td>\n",
       "      <td>...</td>\n",
       "      <td>5.666183e-15</td>\n",
       "      <td>6.482264e-11</td>\n",
       "      <td>3.006606e-20</td>\n",
       "      <td>2.046181e-17</td>\n",
       "      <td>2.526777e-11</td>\n",
       "      <td>3.586842e-20</td>\n",
       "      <td>2.095353e-17</td>\n",
       "      <td>2.498800e-07</td>\n",
       "      <td>7.737464e-14</td>\n",
       "      <td>7.187384e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>982</td>\n",
       "      <td>4.722775e-11</td>\n",
       "      <td>4.104224e-09</td>\n",
       "      <td>3.561998e-09</td>\n",
       "      <td>5.983014e-12</td>\n",
       "      <td>1.128891e-09</td>\n",
       "      <td>6.688430e-07</td>\n",
       "      <td>9.806484e-09</td>\n",
       "      <td>4.962471e-11</td>\n",
       "      <td>3.901492e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.337872e-11</td>\n",
       "      <td>1.880418e-12</td>\n",
       "      <td>1.786577e-14</td>\n",
       "      <td>8.161076e-12</td>\n",
       "      <td>2.167705e-13</td>\n",
       "      <td>2.199732e-15</td>\n",
       "      <td>8.941962e-16</td>\n",
       "      <td>5.253222e-08</td>\n",
       "      <td>5.114311e-09</td>\n",
       "      <td>4.557677e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>1343</td>\n",
       "      <td>3.686431e-10</td>\n",
       "      <td>4.248888e-10</td>\n",
       "      <td>1.239739e-07</td>\n",
       "      <td>5.282607e-07</td>\n",
       "      <td>9.927759e-12</td>\n",
       "      <td>1.586989e-12</td>\n",
       "      <td>1.005376e-10</td>\n",
       "      <td>5.616488e-13</td>\n",
       "      <td>1.044047e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.068882e-12</td>\n",
       "      <td>5.459222e-09</td>\n",
       "      <td>4.670675e-14</td>\n",
       "      <td>1.341372e-06</td>\n",
       "      <td>1.321809e-10</td>\n",
       "      <td>3.180113e-06</td>\n",
       "      <td>9.170746e-14</td>\n",
       "      <td>1.936477e-12</td>\n",
       "      <td>3.975818e-09</td>\n",
       "      <td>7.718174e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>984</td>\n",
       "      <td>1.190038e-10</td>\n",
       "      <td>9.531897e-17</td>\n",
       "      <td>8.997991e-14</td>\n",
       "      <td>4.044057e-06</td>\n",
       "      <td>3.652237e-15</td>\n",
       "      <td>4.862551e-17</td>\n",
       "      <td>1.813667e-15</td>\n",
       "      <td>6.696624e-20</td>\n",
       "      <td>1.078314e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.208627e-13</td>\n",
       "      <td>2.858229e-10</td>\n",
       "      <td>6.339889e-15</td>\n",
       "      <td>1.947846e-10</td>\n",
       "      <td>1.118039e-08</td>\n",
       "      <td>7.187443e-20</td>\n",
       "      <td>3.730556e-15</td>\n",
       "      <td>1.467609e-05</td>\n",
       "      <td>2.442332e-06</td>\n",
       "      <td>3.746624e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>986</td>\n",
       "      <td>2.700300e-14</td>\n",
       "      <td>9.657912e-13</td>\n",
       "      <td>1.040440e-13</td>\n",
       "      <td>7.894053e-13</td>\n",
       "      <td>1.295192e-16</td>\n",
       "      <td>1.232919e-15</td>\n",
       "      <td>6.791472e-09</td>\n",
       "      <td>7.678757e-19</td>\n",
       "      <td>8.251010e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.273686e-18</td>\n",
       "      <td>4.668076e-18</td>\n",
       "      <td>5.683997e-17</td>\n",
       "      <td>8.730273e-17</td>\n",
       "      <td>4.966488e-18</td>\n",
       "      <td>3.197638e-19</td>\n",
       "      <td>4.975678e-21</td>\n",
       "      <td>6.572855e-18</td>\n",
       "      <td>7.627762e-17</td>\n",
       "      <td>1.311810e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>988</td>\n",
       "      <td>6.385814e-10</td>\n",
       "      <td>8.067206e-10</td>\n",
       "      <td>3.483124e-13</td>\n",
       "      <td>2.017574e-03</td>\n",
       "      <td>1.549655e-11</td>\n",
       "      <td>6.618001e-15</td>\n",
       "      <td>2.051267e-12</td>\n",
       "      <td>4.911362e-14</td>\n",
       "      <td>7.890027e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.949684e-11</td>\n",
       "      <td>2.239787e-08</td>\n",
       "      <td>4.734897e-12</td>\n",
       "      <td>2.420768e-11</td>\n",
       "      <td>3.183112e-08</td>\n",
       "      <td>4.186178e-10</td>\n",
       "      <td>1.848268e-13</td>\n",
       "      <td>1.170305e-04</td>\n",
       "      <td>6.427495e-10</td>\n",
       "      <td>2.394842e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>991</td>\n",
       "      <td>3.703034e-12</td>\n",
       "      <td>8.260901e-09</td>\n",
       "      <td>5.721155e-09</td>\n",
       "      <td>9.809066e-10</td>\n",
       "      <td>2.142221e-11</td>\n",
       "      <td>2.753594e-12</td>\n",
       "      <td>1.105554e-13</td>\n",
       "      <td>3.037395e-15</td>\n",
       "      <td>5.316083e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014936e-12</td>\n",
       "      <td>1.173726e-11</td>\n",
       "      <td>5.133974e-11</td>\n",
       "      <td>1.326122e-12</td>\n",
       "      <td>9.951742e-10</td>\n",
       "      <td>4.128391e-10</td>\n",
       "      <td>1.698612e-09</td>\n",
       "      <td>1.022078e-07</td>\n",
       "      <td>2.959185e-07</td>\n",
       "      <td>2.857029e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>1465</td>\n",
       "      <td>8.461752e-10</td>\n",
       "      <td>4.262332e-07</td>\n",
       "      <td>1.476411e-12</td>\n",
       "      <td>1.567262e-10</td>\n",
       "      <td>2.997455e-11</td>\n",
       "      <td>4.070033e-14</td>\n",
       "      <td>1.060236e-06</td>\n",
       "      <td>3.163953e-10</td>\n",
       "      <td>6.047772e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.122751e-08</td>\n",
       "      <td>3.688434e-13</td>\n",
       "      <td>2.407584e-05</td>\n",
       "      <td>7.757099e-09</td>\n",
       "      <td>3.317382e-06</td>\n",
       "      <td>1.883634e-06</td>\n",
       "      <td>1.775354e-01</td>\n",
       "      <td>6.696058e-10</td>\n",
       "      <td>1.124602e-09</td>\n",
       "      <td>1.256062e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>997</td>\n",
       "      <td>9.062993e-10</td>\n",
       "      <td>5.134799e-13</td>\n",
       "      <td>5.702838e-13</td>\n",
       "      <td>1.624809e-10</td>\n",
       "      <td>5.975426e-14</td>\n",
       "      <td>6.151465e-08</td>\n",
       "      <td>1.533441e-09</td>\n",
       "      <td>3.293559e-19</td>\n",
       "      <td>4.670250e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>8.612516e-13</td>\n",
       "      <td>3.372676e-10</td>\n",
       "      <td>7.979808e-14</td>\n",
       "      <td>6.365818e-11</td>\n",
       "      <td>4.154135e-12</td>\n",
       "      <td>2.448547e-18</td>\n",
       "      <td>2.709035e-13</td>\n",
       "      <td>1.984810e-17</td>\n",
       "      <td>2.224735e-09</td>\n",
       "      <td>3.657314e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>998</td>\n",
       "      <td>3.603846e-14</td>\n",
       "      <td>1.784271e-11</td>\n",
       "      <td>2.953228e-08</td>\n",
       "      <td>8.449570e-10</td>\n",
       "      <td>8.733160e-15</td>\n",
       "      <td>1.549652e-11</td>\n",
       "      <td>1.977375e-04</td>\n",
       "      <td>2.499280e-14</td>\n",
       "      <td>4.456593e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>3.630290e-14</td>\n",
       "      <td>3.267604e-15</td>\n",
       "      <td>1.778137e-13</td>\n",
       "      <td>1.247391e-11</td>\n",
       "      <td>4.013272e-14</td>\n",
       "      <td>2.144225e-09</td>\n",
       "      <td>5.588268e-17</td>\n",
       "      <td>1.438047e-16</td>\n",
       "      <td>4.119608e-15</td>\n",
       "      <td>6.341076e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>1361</td>\n",
       "      <td>1.433376e-08</td>\n",
       "      <td>2.143411e-06</td>\n",
       "      <td>5.229942e-14</td>\n",
       "      <td>1.189966e-08</td>\n",
       "      <td>7.231572e-11</td>\n",
       "      <td>2.799643e-14</td>\n",
       "      <td>1.080396e-11</td>\n",
       "      <td>3.208919e-10</td>\n",
       "      <td>2.544413e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.488673e-13</td>\n",
       "      <td>2.686368e-14</td>\n",
       "      <td>4.405610e-09</td>\n",
       "      <td>4.133108e-14</td>\n",
       "      <td>2.383810e-11</td>\n",
       "      <td>4.093181e-08</td>\n",
       "      <td>2.612530e-08</td>\n",
       "      <td>8.398180e-12</td>\n",
       "      <td>1.261119e-13</td>\n",
       "      <td>1.003836e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>1533</td>\n",
       "      <td>5.432875e-12</td>\n",
       "      <td>2.547423e-10</td>\n",
       "      <td>1.978709e-13</td>\n",
       "      <td>1.976805e-05</td>\n",
       "      <td>1.728901e-11</td>\n",
       "      <td>3.085800e-14</td>\n",
       "      <td>3.265248e-09</td>\n",
       "      <td>1.594987e-12</td>\n",
       "      <td>4.138359e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.755748e-15</td>\n",
       "      <td>6.009462e-11</td>\n",
       "      <td>1.408334e-11</td>\n",
       "      <td>1.416334e-12</td>\n",
       "      <td>6.877694e-12</td>\n",
       "      <td>5.172217e-07</td>\n",
       "      <td>5.852293e-13</td>\n",
       "      <td>2.109901e-08</td>\n",
       "      <td>7.140354e-13</td>\n",
       "      <td>2.025150e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>1008</td>\n",
       "      <td>4.007471e-12</td>\n",
       "      <td>4.877091e-15</td>\n",
       "      <td>7.268234e-14</td>\n",
       "      <td>2.745568e-13</td>\n",
       "      <td>2.314334e-17</td>\n",
       "      <td>4.566107e-16</td>\n",
       "      <td>2.035222e-16</td>\n",
       "      <td>1.015580e-18</td>\n",
       "      <td>1.371171e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>9.330808e-16</td>\n",
       "      <td>6.929041e-17</td>\n",
       "      <td>1.874092e-15</td>\n",
       "      <td>3.122991e-13</td>\n",
       "      <td>2.976419e-12</td>\n",
       "      <td>1.322082e-17</td>\n",
       "      <td>7.227497e-17</td>\n",
       "      <td>4.011920e-13</td>\n",
       "      <td>2.459661e-17</td>\n",
       "      <td>5.189027e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>1009</td>\n",
       "      <td>4.316892e-15</td>\n",
       "      <td>2.216341e-09</td>\n",
       "      <td>6.277741e-06</td>\n",
       "      <td>5.385315e-11</td>\n",
       "      <td>4.307258e-13</td>\n",
       "      <td>4.809074e-05</td>\n",
       "      <td>5.087060e-10</td>\n",
       "      <td>2.116926e-16</td>\n",
       "      <td>1.268271e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>7.148547e-12</td>\n",
       "      <td>1.115133e-13</td>\n",
       "      <td>1.402104e-16</td>\n",
       "      <td>1.034662e-11</td>\n",
       "      <td>1.070733e-16</td>\n",
       "      <td>1.651979e-11</td>\n",
       "      <td>1.989914e-15</td>\n",
       "      <td>6.266467e-15</td>\n",
       "      <td>3.211743e-13</td>\n",
       "      <td>5.351094e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>1261</td>\n",
       "      <td>7.678637e-14</td>\n",
       "      <td>8.430823e-18</td>\n",
       "      <td>2.227032e-15</td>\n",
       "      <td>1.697497e-15</td>\n",
       "      <td>4.609826e-14</td>\n",
       "      <td>1.125331e-18</td>\n",
       "      <td>3.247026e-18</td>\n",
       "      <td>1.227327e-18</td>\n",
       "      <td>1.198174e-18</td>\n",
       "      <td>...</td>\n",
       "      <td>4.859425e-15</td>\n",
       "      <td>6.192362e-09</td>\n",
       "      <td>2.652438e-20</td>\n",
       "      <td>4.539326e-14</td>\n",
       "      <td>1.081615e-09</td>\n",
       "      <td>8.090656e-20</td>\n",
       "      <td>3.713443e-18</td>\n",
       "      <td>5.402935e-05</td>\n",
       "      <td>4.620794e-14</td>\n",
       "      <td>3.746745e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>1012</td>\n",
       "      <td>8.066772e-22</td>\n",
       "      <td>9.073615e-13</td>\n",
       "      <td>8.777578e-12</td>\n",
       "      <td>1.362078e-14</td>\n",
       "      <td>1.436827e-17</td>\n",
       "      <td>2.638336e-14</td>\n",
       "      <td>1.064844e-10</td>\n",
       "      <td>2.871230e-23</td>\n",
       "      <td>1.045371e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.085842e-15</td>\n",
       "      <td>5.522373e-17</td>\n",
       "      <td>4.604323e-13</td>\n",
       "      <td>2.036102e-14</td>\n",
       "      <td>1.561997e-10</td>\n",
       "      <td>6.592369e-17</td>\n",
       "      <td>9.096471e-13</td>\n",
       "      <td>1.983439e-10</td>\n",
       "      <td>1.933010e-11</td>\n",
       "      <td>1.774866e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1015</td>\n",
       "      <td>3.886723e-12</td>\n",
       "      <td>8.688714e-16</td>\n",
       "      <td>3.418697e-15</td>\n",
       "      <td>5.827959e-11</td>\n",
       "      <td>5.742098e-17</td>\n",
       "      <td>1.006343e-18</td>\n",
       "      <td>1.080416e-17</td>\n",
       "      <td>7.260115e-14</td>\n",
       "      <td>1.575323e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.204603e-14</td>\n",
       "      <td>4.427292e-17</td>\n",
       "      <td>9.247465e-16</td>\n",
       "      <td>2.638017e-12</td>\n",
       "      <td>2.731564e-13</td>\n",
       "      <td>7.377906e-14</td>\n",
       "      <td>1.266006e-14</td>\n",
       "      <td>2.741566e-12</td>\n",
       "      <td>2.285484e-12</td>\n",
       "      <td>8.913558e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>1018</td>\n",
       "      <td>7.711552e-12</td>\n",
       "      <td>1.908084e-08</td>\n",
       "      <td>2.310094e-09</td>\n",
       "      <td>4.209759e-08</td>\n",
       "      <td>4.451030e-13</td>\n",
       "      <td>5.679397e-13</td>\n",
       "      <td>4.525977e-11</td>\n",
       "      <td>5.549570e-13</td>\n",
       "      <td>3.544806e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.209438e-15</td>\n",
       "      <td>1.407729e-14</td>\n",
       "      <td>1.080452e-12</td>\n",
       "      <td>2.361720e-13</td>\n",
       "      <td>4.287901e-13</td>\n",
       "      <td>1.231615e-09</td>\n",
       "      <td>1.377084e-11</td>\n",
       "      <td>7.449578e-10</td>\n",
       "      <td>1.272747e-08</td>\n",
       "      <td>9.999933e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>1020</td>\n",
       "      <td>3.106145e-09</td>\n",
       "      <td>4.534785e-09</td>\n",
       "      <td>2.618278e-12</td>\n",
       "      <td>1.260228e-03</td>\n",
       "      <td>2.160783e-10</td>\n",
       "      <td>1.894975e-12</td>\n",
       "      <td>2.019072e-10</td>\n",
       "      <td>2.257307e-09</td>\n",
       "      <td>5.294558e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211711e-09</td>\n",
       "      <td>4.193972e-10</td>\n",
       "      <td>1.465118e-11</td>\n",
       "      <td>4.333963e-08</td>\n",
       "      <td>2.419770e-09</td>\n",
       "      <td>4.012494e-06</td>\n",
       "      <td>7.653236e-14</td>\n",
       "      <td>3.914196e-10</td>\n",
       "      <td>4.703947e-10</td>\n",
       "      <td>1.157982e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>1022</td>\n",
       "      <td>1.297485e-11</td>\n",
       "      <td>2.602050e-10</td>\n",
       "      <td>5.556449e-13</td>\n",
       "      <td>1.014593e-08</td>\n",
       "      <td>1.004257e-11</td>\n",
       "      <td>7.002726e-17</td>\n",
       "      <td>2.928397e-15</td>\n",
       "      <td>3.066488e-15</td>\n",
       "      <td>5.055804e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>5.940613e-12</td>\n",
       "      <td>9.622374e-01</td>\n",
       "      <td>3.127516e-16</td>\n",
       "      <td>2.231731e-13</td>\n",
       "      <td>1.026551e-06</td>\n",
       "      <td>1.080854e-15</td>\n",
       "      <td>4.372812e-16</td>\n",
       "      <td>6.367352e-10</td>\n",
       "      <td>6.333035e-11</td>\n",
       "      <td>1.719485e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Acer_Capillipes  Acer_Circinatum     Acer_Mono   Acer_Opalus  \\\n",
       "0    1026     2.869020e-13     1.529277e-10  3.497055e-09  3.752200e-09   \n",
       "1       4     1.159570e-12     8.310549e-13  3.229270e-15  4.123330e-07   \n",
       "2    1029     5.695827e-08     8.574796e-09  6.509347e-11  1.547787e-11   \n",
       "3       7     3.855745e-13     6.281097e-12  1.426525e-11  1.040503e-09   \n",
       "4       9     6.289131e-11     9.998888e-01  9.492183e-11  4.485563e-10   \n",
       "5    1035     1.818157e-11     6.863546e-09  2.173861e-09  4.438699e-08   \n",
       "6      12     1.134462e-14     5.331436e-07  4.497413e-11  1.467479e-13   \n",
       "7      13     4.846606e-12     2.529955e-11  1.497237e-14  2.621346e-14   \n",
       "8    1038     2.175138e-08     5.019227e-11  2.582438e-07  3.543059e-05   \n",
       "9      16     1.413082e-08     7.833825e-10  8.155917e-10  9.796035e-01   \n",
       "10     19     3.960769e-09     2.219355e-09  3.757949e-10  9.999495e-01   \n",
       "11   1044     4.401027e-11     4.745763e-08  7.966423e-14  6.235737e-12   \n",
       "12   1045     3.417634e-07     3.205540e-11  1.112152e-10  5.972434e-08   \n",
       "13     23     1.370218e-14     1.537371e-08  4.375985e-10  8.760763e-09   \n",
       "14     24     3.137803e-09     1.888337e-10  2.719570e-12  8.186363e-15   \n",
       "15   1028     4.535547e-13     7.198407e-13  7.875701e-12  3.723646e-12   \n",
       "16   1050     2.818978e-20     2.630064e-12  4.656703e-14  5.067191e-13   \n",
       "17     28     4.247049e-07     2.558298e-08  7.113322e-11  2.566211e-11   \n",
       "18   1053     1.060605e-12     9.325956e-11  5.856270e-08  5.153778e-12   \n",
       "19   1054     4.746386e-09     1.232027e-14  1.104532e-16  9.782500e-12   \n",
       "20   1055     4.622022e-06     3.410553e-11  7.467886e-18  2.352242e-03   \n",
       "21   1433     1.181753e-13     4.109146e-09  1.150503e-07  5.023456e-09   \n",
       "22     33     1.641425e-11     4.558042e-14  3.473244e-09  1.102278e-08   \n",
       "23   1058     4.192449e-08     1.971057e-08  7.537960e-11  8.589738e-12   \n",
       "24   1371     1.096633e-08     3.420712e-11  1.889570e-13  1.219096e-08   \n",
       "25     36     5.914503e-08     2.544547e-13  5.241738e-12  1.316688e-14   \n",
       "26   1542     1.403831e-05     2.174655e-10  2.638926e-11  1.432329e-06   \n",
       "27     39     1.926356e-09     4.266883e-17  1.594544e-11  4.427570e-11   \n",
       "28   1064     4.361836e-15     3.564977e-13  9.143995e-14  1.159072e-08   \n",
       "29     41     3.682360e-11     2.998908e-12  1.622214e-07  2.369039e-09   \n",
       "..    ...              ...              ...           ...           ...   \n",
       "564   953     2.023934e-15     2.573280e-09  2.556793e-09  1.771523e-08   \n",
       "565  1183     3.414820e-09     2.740715e-09  4.280774e-02  7.448633e-08   \n",
       "566   957     9.026579e-12     1.004403e-09  1.953264e-08  1.944490e-16   \n",
       "567   964     7.954026e-14     1.242175e-19  1.947626e-12  7.756982e-13   \n",
       "568   965     6.022441e-17     2.071268e-10  8.627926e-11  7.136986e-13   \n",
       "569   967     6.826291e-10     1.685481e-08  9.927867e-12  3.237670e-13   \n",
       "570   973     8.771042e-12     1.167048e-10  2.054995e-10  1.230446e-12   \n",
       "571   974     2.671925e-12     1.015591e-12  1.327866e-11  1.464944e-11   \n",
       "572  1215     8.547384e-13     2.068049e-13  5.888669e-10  5.485423e-13   \n",
       "573   977     2.457296e-14     1.245406e-10  3.219755e-08  3.469443e-14   \n",
       "574   980     7.581440e-15     6.880232e-17  7.398001e-13  1.617897e-17   \n",
       "575   982     4.722775e-11     4.104224e-09  3.561998e-09  5.983014e-12   \n",
       "576  1343     3.686431e-10     4.248888e-10  1.239739e-07  5.282607e-07   \n",
       "577   984     1.190038e-10     9.531897e-17  8.997991e-14  4.044057e-06   \n",
       "578   986     2.700300e-14     9.657912e-13  1.040440e-13  7.894053e-13   \n",
       "579   988     6.385814e-10     8.067206e-10  3.483124e-13  2.017574e-03   \n",
       "580   991     3.703034e-12     8.260901e-09  5.721155e-09  9.809066e-10   \n",
       "581  1465     8.461752e-10     4.262332e-07  1.476411e-12  1.567262e-10   \n",
       "582   997     9.062993e-10     5.134799e-13  5.702838e-13  1.624809e-10   \n",
       "583   998     3.603846e-14     1.784271e-11  2.953228e-08  8.449570e-10   \n",
       "584  1361     1.433376e-08     2.143411e-06  5.229942e-14  1.189966e-08   \n",
       "585  1533     5.432875e-12     2.547423e-10  1.978709e-13  1.976805e-05   \n",
       "586  1008     4.007471e-12     4.877091e-15  7.268234e-14  2.745568e-13   \n",
       "587  1009     4.316892e-15     2.216341e-09  6.277741e-06  5.385315e-11   \n",
       "588  1261     7.678637e-14     8.430823e-18  2.227032e-15  1.697497e-15   \n",
       "589  1012     8.066772e-22     9.073615e-13  8.777578e-12  1.362078e-14   \n",
       "590  1015     3.886723e-12     8.688714e-16  3.418697e-15  5.827959e-11   \n",
       "591  1018     7.711552e-12     1.908084e-08  2.310094e-09  4.209759e-08   \n",
       "592  1020     3.106145e-09     4.534785e-09  2.618278e-12  1.260228e-03   \n",
       "593  1022     1.297485e-11     2.602050e-10  5.556449e-13  1.014593e-08   \n",
       "\n",
       "     Acer_Palmatum   Acer_Pictum  Acer_Platanoids   Acer_Rubrum  \\\n",
       "0     8.665882e-09  1.668734e-15     1.253632e-11  1.692365e-10   \n",
       "1     4.229517e-13  1.825746e-16     1.171082e-11  1.719328e-13   \n",
       "2     1.921026e-07  2.038853e-10     1.342976e-05  1.524260e-10   \n",
       "3     1.433467e-10  2.495290e-12     8.599153e-09  1.126502e-11   \n",
       "4     6.429574e-05  5.592501e-09     2.558854e-11  7.623985e-07   \n",
       "5     2.217040e-10  5.321795e-09     8.048378e-13  7.392057e-14   \n",
       "6     4.536607e-10  8.801194e-14     1.253105e-07  8.469607e-12   \n",
       "7     1.929146e-11  4.638825e-16     5.184325e-10  8.176667e-13   \n",
       "8     8.564473e-13  7.389378e-07     6.726415e-08  1.746448e-13   \n",
       "9     4.727880e-09  2.875598e-11     3.462835e-08  3.312818e-06   \n",
       "10    3.095623e-10  6.068299e-12     5.211927e-09  6.510664e-10   \n",
       "11    1.054721e-10  1.982366e-12     1.291552e-10  2.585980e-09   \n",
       "12    3.802777e-10  1.330715e-12     1.175176e-09  2.202643e-10   \n",
       "13    4.705908e-10  3.299784e-07     5.521857e-09  1.752096e-13   \n",
       "14    7.641454e-11  3.272528e-09     1.382859e-08  4.267509e-11   \n",
       "15    4.529923e-11  6.251595e-12     5.565679e-10  5.415494e-13   \n",
       "16    1.659925e-12  1.387737e-08     3.407821e-10  5.075782e-16   \n",
       "17    9.556316e-11  3.339005e-12     4.481532e-09  1.576862e-07   \n",
       "18    2.054121e-12  1.098207e-08     2.126693e-07  3.803406e-12   \n",
       "19    1.155418e-11  7.653384e-16     1.726814e-18  1.290281e-07   \n",
       "20    6.147090e-10  1.491406e-13     1.812504e-13  1.095042e-06   \n",
       "21    7.432354e-11  6.742432e-04     1.463427e-08  2.840008e-14   \n",
       "22    1.645965e-10  9.056058e-10     6.901028e-11  4.331193e-14   \n",
       "23    1.132016e-09  1.430063e-11     6.161581e-11  9.824262e-01   \n",
       "24    1.000394e-09  2.623050e-12     7.360843e-13  3.324607e-10   \n",
       "25    1.118781e-10  2.130657e-12     1.741330e-13  1.742575e-11   \n",
       "26    1.416380e-09  2.185880e-12     4.386292e-10  2.055705e-09   \n",
       "27    1.888961e-15  1.004494e-13     2.145729e-16  1.053228e-14   \n",
       "28    8.589051e-11  6.796306e-13     2.494278e-12  5.706887e-13   \n",
       "29    4.296188e-12  1.227473e-11     4.562128e-11  1.615422e-11   \n",
       "..             ...           ...              ...           ...   \n",
       "564   6.003354e-10  9.288937e-11     1.525636e-07  1.230931e-11   \n",
       "565   7.336368e-09  4.075376e-08     4.550176e-08  1.910461e-09   \n",
       "566   2.110981e-09  4.424295e-07     3.198239e-09  6.985671e-14   \n",
       "567   4.860622e-14  6.312200e-15     8.795291e-18  9.181437e-21   \n",
       "568   1.129920e-09  1.908611e-10     9.999728e-01  1.250714e-11   \n",
       "569   9.152659e-09  6.406066e-07     1.319785e-05  2.428501e-12   \n",
       "570   1.330633e-08  5.357805e-07     2.054533e-07  1.650111e-10   \n",
       "571   6.631848e-12  3.502573e-12     1.478311e-11  1.312714e-12   \n",
       "572   3.155728e-08  1.094599e-06     1.146347e-14  4.458010e-13   \n",
       "573   4.705889e-11  9.993191e-01     6.881924e-10  1.549067e-14   \n",
       "574   1.615814e-12  7.607419e-17     1.779332e-19  8.421961e-17   \n",
       "575   1.128891e-09  6.688430e-07     9.806484e-09  4.962471e-11   \n",
       "576   9.927759e-12  1.586989e-12     1.005376e-10  5.616488e-13   \n",
       "577   3.652237e-15  4.862551e-17     1.813667e-15  6.696624e-20   \n",
       "578   1.295192e-16  1.232919e-15     6.791472e-09  7.678757e-19   \n",
       "579   1.549655e-11  6.618001e-15     2.051267e-12  4.911362e-14   \n",
       "580   2.142221e-11  2.753594e-12     1.105554e-13  3.037395e-15   \n",
       "581   2.997455e-11  4.070033e-14     1.060236e-06  3.163953e-10   \n",
       "582   5.975426e-14  6.151465e-08     1.533441e-09  3.293559e-19   \n",
       "583   8.733160e-15  1.549652e-11     1.977375e-04  2.499280e-14   \n",
       "584   7.231572e-11  2.799643e-14     1.080396e-11  3.208919e-10   \n",
       "585   1.728901e-11  3.085800e-14     3.265248e-09  1.594987e-12   \n",
       "586   2.314334e-17  4.566107e-16     2.035222e-16  1.015580e-18   \n",
       "587   4.307258e-13  4.809074e-05     5.087060e-10  2.116926e-16   \n",
       "588   4.609826e-14  1.125331e-18     3.247026e-18  1.227327e-18   \n",
       "589   1.436827e-17  2.638336e-14     1.064844e-10  2.871230e-23   \n",
       "590   5.742098e-17  1.006343e-18     1.080416e-17  7.260115e-14   \n",
       "591   4.451030e-13  5.679397e-13     4.525977e-11  5.549570e-13   \n",
       "592   2.160783e-10  1.894975e-12     2.019072e-10  2.257307e-09   \n",
       "593   1.004257e-11  7.002726e-17     2.928397e-15  3.066488e-15   \n",
       "\n",
       "     Acer_Rufinerve       ...         Salix_Fragilis  Salix_Intergra  \\\n",
       "0      5.721615e-14       ...           4.268308e-14    9.879059e-07   \n",
       "1      2.621086e-14       ...           4.097174e-14    1.478120e-08   \n",
       "2      1.485938e-05       ...           8.604357e-02    1.091695e-08   \n",
       "3      9.465763e-13       ...           1.065881e-13    1.152906e-12   \n",
       "4      1.593226e-07       ...           3.396650e-10    6.050024e-10   \n",
       "5      1.955893e-14       ...           4.699236e-13    6.840367e-11   \n",
       "6      9.058447e-07       ...           4.105444e-11    1.528023e-12   \n",
       "7      6.479242e-09       ...           1.929581e-10    2.864881e-13   \n",
       "8      1.388468e-13       ...           4.369506e-11    2.025135e-13   \n",
       "9      9.231528e-09       ...           1.673009e-06    1.388219e-07   \n",
       "10     2.638876e-11       ...           4.305484e-11    8.346717e-09   \n",
       "11     1.233317e-11       ...           1.589716e-12    4.071024e-14   \n",
       "12     4.700801e-11       ...           3.024813e-11    4.622029e-11   \n",
       "13     2.018483e-15       ...           1.822858e-12    7.754210e-12   \n",
       "14     1.148087e-07       ...           5.292301e-12    4.817293e-14   \n",
       "15     7.816946e-12       ...           6.928958e-12    2.818562e-08   \n",
       "16     5.293439e-14       ...           4.455725e-16    3.861079e-18   \n",
       "17     9.999981e-01       ...           7.559344e-09    1.797289e-10   \n",
       "18     1.811211e-08       ...           6.530509e-13    3.297032e-13   \n",
       "19     3.847565e-11       ...           8.733175e-08    1.627425e-15   \n",
       "20     2.422826e-05       ...           9.975854e-01    1.727756e-10   \n",
       "21     2.410637e-11       ...           9.206077e-12    8.509545e-14   \n",
       "22     2.566565e-16       ...           1.941523e-10    2.010456e-11   \n",
       "23     1.288592e-05       ...           1.672771e-05    2.333090e-11   \n",
       "24     6.311306e-10       ...           9.633766e-14    1.515068e-15   \n",
       "25     1.533813e-10       ...           1.519011e-15    5.147142e-16   \n",
       "26     1.826604e-09       ...           2.482801e-09    4.308499e-10   \n",
       "27     1.074267e-15       ...           1.193598e-11    2.776112e-09   \n",
       "28     6.558697e-13       ...           1.723864e-13    2.687968e-10   \n",
       "29     7.279345e-13       ...           1.786440e-10    2.645171e-11   \n",
       "..              ...       ...                    ...             ...   \n",
       "564    1.388125e-13       ...           1.970403e-10    5.689527e-09   \n",
       "565    7.577875e-12       ...           7.062905e-10    8.729872e-08   \n",
       "566    7.759068e-11       ...           1.994141e-12    1.907357e-12   \n",
       "567    4.228698e-17       ...           6.378516e-13    1.516194e-12   \n",
       "568    1.191870e-10       ...           1.462782e-11    1.251153e-10   \n",
       "569    2.580002e-12       ...           3.116250e-10    1.183391e-09   \n",
       "570    3.260041e-09       ...           2.639530e-11    4.196896e-09   \n",
       "571    2.989797e-11       ...           2.853260e-11    4.170106e-09   \n",
       "572    4.214816e-12       ...           1.269145e-09    2.770870e-11   \n",
       "573    5.842826e-15       ...           3.653523e-12    1.319033e-16   \n",
       "574    1.167653e-20       ...           5.666183e-15    6.482264e-11   \n",
       "575    3.901492e-10       ...           2.337872e-11    1.880418e-12   \n",
       "576    1.044047e-10       ...           5.068882e-12    5.459222e-09   \n",
       "577    1.078314e-17       ...           2.208627e-13    2.858229e-10   \n",
       "578    8.251010e-09       ...           1.273686e-18    4.668076e-18   \n",
       "579    7.890027e-11       ...           1.949684e-11    2.239787e-08   \n",
       "580    5.316083e-11       ...           1.014936e-12    1.173726e-11   \n",
       "581    6.047772e-07       ...           1.122751e-08    3.688434e-13   \n",
       "582    4.670250e-14       ...           8.612516e-13    3.372676e-10   \n",
       "583    4.456593e-11       ...           3.630290e-14    3.267604e-15   \n",
       "584    2.544413e-09       ...           1.488673e-13    2.686368e-14   \n",
       "585    4.138359e-12       ...           1.755748e-15    6.009462e-11   \n",
       "586    1.371171e-14       ...           9.330808e-16    6.929041e-17   \n",
       "587    1.268271e-14       ...           7.148547e-12    1.115133e-13   \n",
       "588    1.198174e-18       ...           4.859425e-15    6.192362e-09   \n",
       "589    1.045371e-17       ...           1.085842e-15    5.522373e-17   \n",
       "590    1.575323e-15       ...           1.204603e-14    4.427292e-17   \n",
       "591    3.544806e-14       ...           1.209438e-15    1.407729e-14   \n",
       "592    5.294558e-08       ...           1.211711e-09    4.193972e-10   \n",
       "593    5.055804e-15       ...           5.940613e-12    9.622374e-01   \n",
       "\n",
       "      Sorbus_Aria  Tilia_Oliveri  Tilia_Platyphyllos  Tilia_Tomentosa  \\\n",
       "0    5.018530e-12   3.757866e-09        6.097649e-06     1.296256e-09   \n",
       "1    2.576582e-12   1.178369e-13        6.354355e-10     4.283691e-14   \n",
       "2    1.416735e-04   5.031326e-08        2.656954e-05     4.285481e-06   \n",
       "3    6.107722e-13   7.608827e-13        2.042700e-13     6.974107e-09   \n",
       "4    1.039362e-10   1.682971e-11        9.298544e-15     1.238260e-10   \n",
       "5    4.944857e-11   2.903605e-12        1.078269e-11     1.067115e-10   \n",
       "6    1.819910e-09   1.115343e-11        4.180719e-11     1.226446e-08   \n",
       "7    3.057113e-08   2.215729e-11        7.997122e-08     2.561640e-09   \n",
       "8    1.079750e-10   1.002365e-11        6.731412e-14     2.736050e-09   \n",
       "9    7.266534e-08   1.893304e-07        4.795458e-06     5.396638e-06   \n",
       "10   3.677640e-09   3.945712e-09        7.765190e-08     2.066146e-06   \n",
       "11   8.526528e-08   1.205601e-13        2.838558e-12     1.024325e-09   \n",
       "12   1.799297e-06   1.234780e-08        2.315443e-06     8.428933e-10   \n",
       "13   3.424814e-13   2.707355e-13        1.114967e-09     3.281941e-13   \n",
       "14   1.461676e-13   4.840254e-10        1.055768e-13     5.479237e-14   \n",
       "15   4.127446e-11   3.180722e-09        1.793761e-09     8.041601e-11   \n",
       "16   1.299239e-17   3.698943e-17        9.800023e-19     2.130848e-14   \n",
       "17   2.448060e-08   5.513813e-11        7.768745e-10     5.751609e-07   \n",
       "18   5.788538e-12   1.120405e-13        1.074327e-16     1.688173e-12   \n",
       "19   1.915426e-12   4.875493e-10        6.133196e-09     1.135355e-15   \n",
       "20   9.244686e-09   6.319249e-11        2.609683e-05     1.349412e-06   \n",
       "21   3.019739e-13   1.251737e-13        1.445862e-12     9.297333e-14   \n",
       "22   1.594813e-10   1.603333e-08        1.294943e-10     3.692892e-17   \n",
       "23   6.816097e-08   1.628511e-05        1.425376e-11     2.764155e-07   \n",
       "24   1.660768e-07   7.292880e-14        3.841548e-09     4.747549e-11   \n",
       "25   7.473930e-10   7.190707e-14        1.218199e-11     1.254371e-15   \n",
       "26   8.177479e-07   6.525383e-09        3.832788e-05     1.643768e-10   \n",
       "27   1.205791e-16   1.143935e-09        1.013255e-13     5.976735e-16   \n",
       "28   5.204750e-13   3.046539e-15        1.488609e-09     1.898028e-09   \n",
       "29   1.522006e-13   1.227608e-08        7.384722e-12     4.432539e-06   \n",
       "..            ...            ...                 ...              ...   \n",
       "564  2.491832e-12   1.132712e-07        1.653039e-09     8.393832e-09   \n",
       "565  3.120578e-12   2.561588e-07        7.937396e-12     9.878034e-06   \n",
       "566  3.925019e-13   3.458607e-10        1.327410e-14     1.414658e-14   \n",
       "567  3.393554e-13   1.671330e-10        8.078315e-10     4.867039e-23   \n",
       "568  3.342492e-14   3.734351e-09        2.536342e-11     3.010827e-10   \n",
       "569  2.098204e-11   2.459242e-08        1.507103e-08     6.702275e-12   \n",
       "570  2.848672e-11   1.389929e-08        1.109116e-09     2.873393e-10   \n",
       "571  2.073386e-12   1.851764e-11        1.721952e-09     4.940948e-11   \n",
       "572  1.823678e-11   4.726436e-07        3.718997e-11     4.700438e-14   \n",
       "573  2.070559e-16   6.724311e-14        1.023536e-16     2.370604e-13   \n",
       "574  3.006606e-20   2.046181e-17        2.526777e-11     3.586842e-20   \n",
       "575  1.786577e-14   8.161076e-12        2.167705e-13     2.199732e-15   \n",
       "576  4.670675e-14   1.341372e-06        1.321809e-10     3.180113e-06   \n",
       "577  6.339889e-15   1.947846e-10        1.118039e-08     7.187443e-20   \n",
       "578  5.683997e-17   8.730273e-17        4.966488e-18     3.197638e-19   \n",
       "579  4.734897e-12   2.420768e-11        3.183112e-08     4.186178e-10   \n",
       "580  5.133974e-11   1.326122e-12        9.951742e-10     4.128391e-10   \n",
       "581  2.407584e-05   7.757099e-09        3.317382e-06     1.883634e-06   \n",
       "582  7.979808e-14   6.365818e-11        4.154135e-12     2.448547e-18   \n",
       "583  1.778137e-13   1.247391e-11        4.013272e-14     2.144225e-09   \n",
       "584  4.405610e-09   4.133108e-14        2.383810e-11     4.093181e-08   \n",
       "585  1.408334e-11   1.416334e-12        6.877694e-12     5.172217e-07   \n",
       "586  1.874092e-15   3.122991e-13        2.976419e-12     1.322082e-17   \n",
       "587  1.402104e-16   1.034662e-11        1.070733e-16     1.651979e-11   \n",
       "588  2.652438e-20   4.539326e-14        1.081615e-09     8.090656e-20   \n",
       "589  4.604323e-13   2.036102e-14        1.561997e-10     6.592369e-17   \n",
       "590  9.247465e-16   2.638017e-12        2.731564e-13     7.377906e-14   \n",
       "591  1.080452e-12   2.361720e-13        4.287901e-13     1.231615e-09   \n",
       "592  1.465118e-11   4.333963e-08        2.419770e-09     4.012494e-06   \n",
       "593  3.127516e-16   2.231731e-13        1.026551e-06     1.080854e-15   \n",
       "\n",
       "     Ulmus_Bergmanniana  Viburnum_Tinus  Viburnum_x_Rhytidophylloides  \\\n",
       "0          3.317226e-14    6.300510e-06                  4.647927e-09   \n",
       "1          1.008377e-15    1.131792e-14                  2.047118e-13   \n",
       "2          9.209554e-03    1.420646e-08                  1.433977e-08   \n",
       "3          2.163322e-13    1.269684e-09                  3.280878e-13   \n",
       "4          2.479792e-10    1.954589e-13                  9.756926e-13   \n",
       "5          5.698240e-11    1.130901e-09                  1.218257e-08   \n",
       "6          1.039584e-04    1.779851e-10                  4.638010e-10   \n",
       "7          2.334679e-07    8.070605e-10                  4.601576e-12   \n",
       "8          1.360797e-13    2.705563e-15                  3.459092e-10   \n",
       "9          8.016678e-10    1.999327e-09                  5.937847e-06   \n",
       "10         9.740824e-12    1.570086e-09                  6.575967e-08   \n",
       "11         1.220956e-07    4.031406e-11                  8.599151e-13   \n",
       "12         5.190981e-11    5.744465e-12                  2.439979e-09   \n",
       "13         4.509813e-15    1.982658e-11                  1.023958e-11   \n",
       "14         5.008979e-15    5.013352e-17                  4.756175e-15   \n",
       "15         1.960803e-11    1.759034e-11                  7.883532e-12   \n",
       "16         1.293216e-18    4.190189e-17                  2.199124e-15   \n",
       "17         2.145429e-09    3.217214e-16                  2.655700e-13   \n",
       "18         5.972809e-16    1.322741e-16                  1.447215e-13   \n",
       "19         4.073993e-10    6.183092e-16                  6.411148e-14   \n",
       "20         2.333383e-09    3.421780e-15                  2.285414e-14   \n",
       "21         3.845387e-12    1.421198e-10                  1.048826e-09   \n",
       "22         8.971643e-10    6.487788e-06                  3.817768e-05   \n",
       "23         2.121873e-05    4.059649e-16                  1.439874e-12   \n",
       "24         5.632530e-12    1.397190e-11                  7.461164e-12   \n",
       "25         2.665548e-13    2.764684e-12                  4.397991e-13   \n",
       "26         3.859595e-10    8.484144e-12                  3.029612e-09   \n",
       "27         1.734955e-16    4.099796e-11                  9.197889e-11   \n",
       "28         1.333933e-15    3.535191e-09                  3.030722e-12   \n",
       "29         7.984902e-14    2.508790e-16                  4.366366e-12   \n",
       "..                  ...             ...                           ...   \n",
       "564        8.442339e-09    1.094370e-05                  3.648587e-07   \n",
       "565        1.058862e-11    3.174023e-11                  4.702815e-08   \n",
       "566        1.921762e-13    4.466084e-17                  6.552594e-12   \n",
       "567        1.085370e-12    2.433580e-05                  1.512051e-06   \n",
       "568        3.156212e-13    3.292189e-11                  1.061628e-13   \n",
       "569        4.888084e-11    5.657998e-13                  1.885649e-12   \n",
       "570        1.533482e-10    5.922913e-11                  1.708045e-11   \n",
       "571        8.207446e-11    3.214864e-13                  3.870720e-13   \n",
       "572        2.437842e-08    2.505690e-07                  3.659023e-10   \n",
       "573        6.603811e-16    4.019022e-15                  1.240068e-14   \n",
       "574        2.095353e-17    2.498800e-07                  7.737464e-14   \n",
       "575        8.941962e-16    5.253222e-08                  5.114311e-09   \n",
       "576        9.170746e-14    1.936477e-12                  3.975818e-09   \n",
       "577        3.730556e-15    1.467609e-05                  2.442332e-06   \n",
       "578        4.975678e-21    6.572855e-18                  7.627762e-17   \n",
       "579        1.848268e-13    1.170305e-04                  6.427495e-10   \n",
       "580        1.698612e-09    1.022078e-07                  2.959185e-07   \n",
       "581        1.775354e-01    6.696058e-10                  1.124602e-09   \n",
       "582        2.709035e-13    1.984810e-17                  2.224735e-09   \n",
       "583        5.588268e-17    1.438047e-16                  4.119608e-15   \n",
       "584        2.612530e-08    8.398180e-12                  1.261119e-13   \n",
       "585        5.852293e-13    2.109901e-08                  7.140354e-13   \n",
       "586        7.227497e-17    4.011920e-13                  2.459661e-17   \n",
       "587        1.989914e-15    6.266467e-15                  3.211743e-13   \n",
       "588        3.713443e-18    5.402935e-05                  4.620794e-14   \n",
       "589        9.096471e-13    1.983439e-10                  1.933010e-11   \n",
       "590        1.266006e-14    2.741566e-12                  2.285484e-12   \n",
       "591        1.377084e-11    7.449578e-10                  1.272747e-08   \n",
       "592        7.653236e-14    3.914196e-10                  4.703947e-10   \n",
       "593        4.372812e-16    6.367352e-10                  6.333035e-11   \n",
       "\n",
       "     Zelkova_Serrata  \n",
       "0       5.881330e-06  \n",
       "1       6.398953e-14  \n",
       "2       2.518181e-09  \n",
       "3       1.685711e-08  \n",
       "4       1.767668e-05  \n",
       "5       1.763703e-09  \n",
       "6       1.362704e-05  \n",
       "7       1.653976e-13  \n",
       "8       4.684759e-10  \n",
       "9       6.150653e-08  \n",
       "10      2.098754e-05  \n",
       "11      2.292317e-07  \n",
       "12      1.518916e-11  \n",
       "13      1.794373e-10  \n",
       "14      2.124232e-14  \n",
       "15      2.923086e-16  \n",
       "16      2.329780e-18  \n",
       "17      3.308940e-09  \n",
       "18      2.120400e-13  \n",
       "19      8.590073e-16  \n",
       "20      2.138086e-12  \n",
       "21      2.575307e-12  \n",
       "22      3.845432e-09  \n",
       "23      4.855786e-10  \n",
       "24      1.244433e-09  \n",
       "25      2.387567e-11  \n",
       "26      1.212928e-12  \n",
       "27      6.522774e-12  \n",
       "28      7.498612e-10  \n",
       "29      1.075103e-10  \n",
       "..               ...  \n",
       "564     4.278555e-10  \n",
       "565     1.509644e-05  \n",
       "566     7.014383e-16  \n",
       "567     9.616634e-13  \n",
       "568     6.805103e-11  \n",
       "569     7.580645e-13  \n",
       "570     2.830382e-11  \n",
       "571     2.593558e-17  \n",
       "572     3.606462e-17  \n",
       "573     3.929130e-14  \n",
       "574     7.187384e-16  \n",
       "575     4.557677e-11  \n",
       "576     7.718174e-07  \n",
       "577     3.746624e-10  \n",
       "578     1.311810e-15  \n",
       "579     2.394842e-08  \n",
       "580     2.857029e-07  \n",
       "581     1.256062e-06  \n",
       "582     3.657314e-17  \n",
       "583     6.341076e-13  \n",
       "584     1.003836e-06  \n",
       "585     2.025150e-06  \n",
       "586     5.189027e-21  \n",
       "587     5.351094e-12  \n",
       "588     3.746745e-15  \n",
       "589     1.774866e-14  \n",
       "590     8.913558e-13  \n",
       "591     9.999933e-01  \n",
       "592     1.157982e-08  \n",
       "593     1.719485e-11  \n",
       "\n",
       "[594 rows x 100 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = pd.DataFrame(preds_test, columns=data.le.classes_)\n",
    "ids_test_df = pd.DataFrame(ids_test, columns=[\"id\"])\n",
    "submission = pd.concat([ids_test_df, preds_df], axis=1)\n",
    "submission.to_csv('submission_mlp.csv', index=False)\n",
    "# below prints the submission, can be removed and replaced with code block below\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
